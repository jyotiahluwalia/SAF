{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4773df8-7bf8-4512-83e4-3c0bbc20fa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.1\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()  }\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f40ce96-fe45-4f7e-8787-e2cccfc5dc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMengine: 0.10.4\n",
      "Openmim: 0.3.9\n",
      "mmcv: 2.0.0rc4\n",
      "mmdetection: 3.3.0\n"
     ]
    }
   ],
   "source": [
    "# Check mmengine installation\n",
    "import mmengine\n",
    "print(f\"MMengine: {mmengine.__version__}\")\n",
    "\n",
    "# Check Openmim installation\n",
    "from importlib.metadata import version\n",
    "print(f\"Openmim: {version('openmim')}\")\n",
    "\n",
    "# Check mmcv installation\n",
    "import mmcv\n",
    "print(\"mmcv:\",mmcv.__version__)\n",
    "\n",
    "# Check MMDetection installation\n",
    "import mmdet\n",
    "print(\"mmdetection:\",mmdet.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3cfa7f3-6288-47df-8c25-4db8db0ad051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: mmdetection/configs/htc/htc_x101_32x4d_fpn_16x1_20e_coco_20200318-de97ae01.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: roi_head.semantic_head.lateral_convs.0.conv.weight, roi_head.semantic_head.lateral_convs.0.conv.bias, roi_head.semantic_head.lateral_convs.1.conv.weight, roi_head.semantic_head.lateral_convs.1.conv.bias, roi_head.semantic_head.lateral_convs.2.conv.weight, roi_head.semantic_head.lateral_convs.2.conv.bias, roi_head.semantic_head.lateral_convs.3.conv.weight, roi_head.semantic_head.lateral_convs.3.conv.bias, roi_head.semantic_head.lateral_convs.4.conv.weight, roi_head.semantic_head.lateral_convs.4.conv.bias, roi_head.semantic_head.convs.0.conv.weight, roi_head.semantic_head.convs.0.conv.bias, roi_head.semantic_head.convs.1.conv.weight, roi_head.semantic_head.convs.1.conv.bias, roi_head.semantic_head.convs.2.conv.weight, roi_head.semantic_head.convs.2.conv.bias, roi_head.semantic_head.convs.3.conv.weight, roi_head.semantic_head.convs.3.conv.bias, roi_head.semantic_head.conv_embedding.conv.weight, roi_head.semantic_head.conv_embedding.conv.bias, roi_head.semantic_head.conv_logits.weight, roi_head.semantic_head.conv_logits.bias\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "import mmengine\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmdet.utils import register_all_modules\n",
    "# Choose to use a config and initialize the detector\n",
    "config_file = 'mmdetection/configs/htc/htc_x101-32x4d_fpn_16xb1-20e_coco.py'\n",
    "# Setup a checkpoint file to load\n",
    "checkpoint_file = 'mmdetection/configs/htc/htc_x101_32x4d_fpn_16x1_20e_coco_20200318-de97ae01.pth'\n",
    "\n",
    "# register all modules in mmdet into the registries\n",
    "register_all_modules()\n",
    "\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')  # or device='cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92bdd4fa-8477-4b21-9b4f-90c900d95907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Category ID: 1, Category Name: ClassicalEvaporation\n",
      "Category ID: 2, Category Name: TansitionalMixing\n",
      "Category ID: 3, Category Name: DiffusiveMixing\n",
      "Category ID: 4, Category Name: spray\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Path to load the COCO annotation file\n",
    "annotation_file = 'mmdetection/data/saf22/train/annotation_coco.json'\n",
    "\n",
    "# Initialise the COCO object\n",
    "coco = COCO(annotation_file)\n",
    "\n",
    "# Get all category tags and corresponding category IDs\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "category_id_to_name = {cat['id']: cat['name'] for cat in categories}\n",
    "\n",
    "# Print all category IDs and corresponding category names\n",
    "for category_id, category_name in category_id_to_name.items():\n",
    "    print(f\"Category ID: {category_id}, Category Name: {category_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45316c5-ae78-4366-8ce5-042e41400a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb8bcc6a-c806-416a-b76b-59dfb2228ef1",
   "metadata": {},
   "source": [
    "### Wandb integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6fe0087-45b6-4d76-a2cb-5e84887474d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: ahluwaliajyoti50 (ahluwaliajyoti50-university-of-sussex). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6683279b-302d-4073-819b-eedb1f6dc611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17.5\n"
     ]
    }
   ],
   "source": [
    "# Weights and Biases version\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b0d71-3692-401b-89d6-80b692f4f2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7e14d58-20d8-43d6-a411-c20df33d7776",
   "metadata": {},
   "source": [
    "# Medium with epoch size - 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ebf91c3-4925-4c3d-a76a-66c3029146d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.runner import set_random_seed\n",
    "from mmengine import Config\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mmdet.visualization import DetLocalVisualizer\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb4e8fe-f0b1-4d0d-9570-2db796b4928f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2980d642-a344-4519-9664-f5e956748aea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/07 18:34:18 - mmengine - INFO - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 209652396\n",
      "    GPU 0: NVIDIA RTX A4000\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.66\n",
      "    MSVC: n/a, reason: fileno\n",
      "    PyTorch: 2.3.1\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 201703\n",
      "  - MSVC 192930154\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.7  (built against CUDA 12.2)\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.7, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.18.1\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 209652396\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/07 18:34:19 - mmengine - INFO - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'mmdetection/data/saf22/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=1,\n",
      "        max_keep_ckpts=1,\n",
      "        rule='greater',\n",
      "        save_best=[\n",
      "            'coco/bbox_mAP',\n",
      "            'coco/segm_mAP',\n",
      "        ],\n",
      "        save_last=True,\n",
      "        save_optimizer=True,\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "launcher = 'none'\n",
      "load_from = 'mmdetection/configs/htc/htc_x101_32x4d_fpn_16x1_20e_coco_20200318-de97ae01.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 20\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'ClassicalEvaporation',\n",
      "        'TansitionalMixing',\n",
      "        'DiffusiveMixing',\n",
      "        'spray',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            13,\n",
      "            24,\n",
      "            103,\n",
      "        ),\n",
      "        (\n",
      "            167,\n",
      "            13,\n",
      "            13,\n",
      "        ),\n",
      "        (\n",
      "            91,\n",
      "            117,\n",
      "            249,\n",
      "        ),\n",
      "        (\n",
      "            203,\n",
      "            173,\n",
      "            55,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_seg=True,\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                        0.2,\n",
      "                        0.2,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=4,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.05,\n",
      "                        0.05,\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=4,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.033,\n",
      "                        0.033,\n",
      "                        0.067,\n",
      "                        0.067,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=4,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "        ],\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        interleaved=True,\n",
      "        mask_head=[\n",
      "            dict(\n",
      "                conv_out_channels=256,\n",
      "                in_channels=256,\n",
      "                loss_mask=dict(\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "                num_classes=4,\n",
      "                num_convs=4,\n",
      "                type='HTCMaskHead',\n",
      "                with_conv_res=False),\n",
      "            dict(\n",
      "                conv_out_channels=256,\n",
      "                in_channels=256,\n",
      "                loss_mask=dict(\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "                num_classes=4,\n",
      "                num_convs=4,\n",
      "                type='HTCMaskHead'),\n",
      "            dict(\n",
      "                conv_out_channels=256,\n",
      "                in_channels=256,\n",
      "                loss_mask=dict(\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "                num_classes=4,\n",
      "                num_convs=4,\n",
      "                type='HTCMaskHead'),\n",
      "        ],\n",
      "        mask_info_flow=True,\n",
      "        mask_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        num_stages=3,\n",
      "        semantic_head=None,\n",
      "        semantic_roi_extractor=None,\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            0.5,\n",
      "            0.25,\n",
      "        ],\n",
      "        type='HybridTaskCascadeRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(\n",
      "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            mask_thr_binary=0.5,\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.001),\n",
      "        rpn=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=1000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    pos_iou_thr=0.5,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    pos_iou_thr=0.6,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    pos_iou_thr=0.7,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "        ],\n",
      "        rpn=dict(\n",
      "            allowed_border=0,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    type='HybridTaskCascade')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.0025, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=20,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            16,\n",
      "            19,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='val/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val/'),\n",
      "        data_root='mmdetection/data/saf22/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'ClassicalEvaporation',\n",
      "                'TansitionalMixing',\n",
      "                'DiffusiveMixing',\n",
      "                'spray',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    13,\n",
      "                    24,\n",
      "                    103,\n",
      "                ),\n",
      "                (\n",
      "                    167,\n",
      "                    13,\n",
      "                    13,\n",
      "                ),\n",
      "                (\n",
      "                    91,\n",
      "                    117,\n",
      "                    249,\n",
      "                ),\n",
      "                (\n",
      "                    203,\n",
      "                    173,\n",
      "                    55,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='mmdetection/data/saf22/val/annotation_coco.json',\n",
      "    backend_args=None,\n",
      "    classwise=True,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=20, type='EpochBasedTrainLoop', val_interval=3)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='train/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='train/'),\n",
      "        data_root='mmdetection/data/saf22/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'ClassicalEvaporation',\n",
      "                'TansitionalMixing',\n",
      "                'DiffusiveMixing',\n",
      "                'spray',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    13,\n",
      "                    24,\n",
      "                    103,\n",
      "                ),\n",
      "                (\n",
      "                    167,\n",
      "                    13,\n",
      "                    13,\n",
      "                ),\n",
      "                (\n",
      "                    91,\n",
      "                    117,\n",
      "                    249,\n",
      "                ),\n",
      "                (\n",
      "                    203,\n",
      "                    173,\n",
      "                    55,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='LoadAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_mask=True,\n",
      "                with_seg=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='val/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val/'),\n",
      "        data_root='mmdetection/data/saf22/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'ClassicalEvaporation',\n",
      "                'TansitionalMixing',\n",
      "                'DiffusiveMixing',\n",
      "                'spray',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    13,\n",
      "                    24,\n",
      "                    103,\n",
      "                ),\n",
      "                (\n",
      "                    167,\n",
      "                    13,\n",
      "                    13,\n",
      "                ),\n",
      "                (\n",
      "                    91,\n",
      "                    117,\n",
      "                    249,\n",
      "                ),\n",
      "                (\n",
      "                    203,\n",
      "                    173,\n",
      "                    55,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='mmdetection/data/saf22/val/annotation_coco.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(type='TensorboardVisBackend'),\n",
      "        dict(\n",
      "            init_kwargs=dict(\n",
      "                config=dict(\n",
      "                    architecture='HTC_X101',\n",
      "                    batch_size=1,\n",
      "                    classes=(\n",
      "                        'ClassicalEvaporation',\n",
      "                        'TansitionalMixing',\n",
      "                        'DiffusiveMixing',\n",
      "                        'spray',\n",
      "                    ),\n",
      "                    dataset='SAF22',\n",
      "                    epochs=20,\n",
      "                    learning_rate=0.0025,\n",
      "                    optimizer='SGD',\n",
      "                    seed=0),\n",
      "                entity='ahluwaliajyoti50-university-of-sussex',\n",
      "                project='SAF_Project'),\n",
      "            type='WandbVisBackend'),\n",
      "    ])\n",
      "work_dir = './tutorial_exps/20-epochs-benchmark'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ja683\\Downloads\\saf\\tutorial_exps\\20-epochs-benchmark\\20240807_183412\\vis_data\\wandb\\run-20240807_183420-ai7tlr1m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project/runs/ai7tlr1m' target=\"_blank\">avid-planet-51</a></strong> to <a href='https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project' target=\"_blank\">https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project/runs/ai7tlr1m' target=\"_blank\">https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project/runs/ai7tlr1m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/07 18:34:36 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/07 18:34:36 - mmengine - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.46s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "08/07 18:34:47 - mmengine - INFO - load model from: open-mmlab://resnext101_32x4d\n",
      "08/07 18:34:47 - mmengine - INFO - Loads checkpoint by openmmlab backend from path: open-mmlab://resnext101_32x4d\n",
      "Loads checkpoint by local backend from path: mmdetection/configs/htc/htc_x101_32x4d_fpn_16x1_20e_coco_20200318-de97ae01.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.0.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([5, 1024]).\n",
      "size mismatch for roi_head.bbox_head.0.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([5]).\n",
      "size mismatch for roi_head.bbox_head.1.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([5, 1024]).\n",
      "size mismatch for roi_head.bbox_head.1.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([5]).\n",
      "size mismatch for roi_head.bbox_head.2.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([5, 1024]).\n",
      "size mismatch for roi_head.bbox_head.2.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([5]).\n",
      "size mismatch for roi_head.mask_head.0.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([4, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.0.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([4]).\n",
      "size mismatch for roi_head.mask_head.1.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([4, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.1.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([4]).\n",
      "size mismatch for roi_head.mask_head.2.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([4, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.2.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([4]).\n",
      "unexpected key in source state_dict: roi_head.semantic_head.lateral_convs.0.conv.weight, roi_head.semantic_head.lateral_convs.0.conv.bias, roi_head.semantic_head.lateral_convs.1.conv.weight, roi_head.semantic_head.lateral_convs.1.conv.bias, roi_head.semantic_head.lateral_convs.2.conv.weight, roi_head.semantic_head.lateral_convs.2.conv.bias, roi_head.semantic_head.lateral_convs.3.conv.weight, roi_head.semantic_head.lateral_convs.3.conv.bias, roi_head.semantic_head.lateral_convs.4.conv.weight, roi_head.semantic_head.lateral_convs.4.conv.bias, roi_head.semantic_head.convs.0.conv.weight, roi_head.semantic_head.convs.0.conv.bias, roi_head.semantic_head.convs.1.conv.weight, roi_head.semantic_head.convs.1.conv.bias, roi_head.semantic_head.convs.2.conv.weight, roi_head.semantic_head.convs.2.conv.bias, roi_head.semantic_head.convs.3.conv.weight, roi_head.semantic_head.convs.3.conv.bias, roi_head.semantic_head.conv_embedding.conv.weight, roi_head.semantic_head.conv_embedding.conv.bias, roi_head.semantic_head.conv_logits.weight, roi_head.semantic_head.conv_logits.bias\n",
      "\n",
      "08/07 18:34:48 - mmengine - INFO - Load checkpoint from mmdetection/configs/htc/htc_x101_32x4d_fpn_16x1_20e_coco_20200318-de97ae01.pth\n",
      "08/07 18:34:48 - mmengine - WARNING - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/07 18:34:48 - mmengine - WARNING - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "08/07 18:34:48 - mmengine - INFO - Checkpoints will be saved to C:\\Users\\ja683\\Downloads\\saf\\tutorial_exps\\20-epochs-benchmark.\n",
      "08/07 18:35:59 - mmengine - INFO - Epoch(train)  [1][10/36]  lr: 4.7545e-05  eta: 1:23:17  time: 7.0393  data_time: 4.9118  memory: 4868  loss: 4.0716  loss_rpn_cls: 0.0025  loss_rpn_bbox: 0.0017  s0.loss_cls: 1.4586  s0.acc: 86.9141  s0.loss_bbox: 0.0124  s0.loss_mask: 0.6802  s1.loss_cls: 0.8472  s1.acc: 5.2734  s1.loss_bbox: 0.0141  s1.loss_mask: 0.4034  s2.loss_cls: 0.3915  s2.acc: 16.9922  s2.loss_bbox: 0.0087  s2.loss_mask: 0.2512\n",
      "08/07 18:36:02 - mmengine - INFO - Epoch(train)  [1][20/36]  lr: 9.7595e-05  eta: 0:42:57  time: 3.6827  data_time: 2.4631  memory: 4134  loss: 3.7538  loss_rpn_cls: 0.0032  loss_rpn_bbox: 0.0014  s0.loss_cls: 1.2762  s0.acc: 97.0703  s0.loss_bbox: 0.0119  s0.loss_mask: 0.6859  s1.loss_cls: 0.7630  s1.acc: 97.0703  s1.loss_bbox: 0.0125  s1.loss_mask: 0.3968  s2.loss_cls: 0.3599  s2.acc: 97.0703  s2.loss_bbox: 0.0073  s2.loss_mask: 0.2358\n",
      "08/07 18:36:06 - mmengine - INFO - Epoch(train)  [1][30/36]  lr: 1.4765e-04  eta: 0:29:42  time: 2.5827  data_time: 1.6526  memory: 4470  loss: 3.3730  loss_rpn_cls: 0.0390  loss_rpn_bbox: 0.0014  s0.loss_cls: 1.0527  s0.acc: 95.8984  s0.loss_bbox: 0.0106  s0.loss_mask: 0.6791  s1.loss_cls: 0.6360  s1.acc: 96.0938  s1.loss_bbox: 0.0118  s1.loss_mask: 0.3925  s2.loss_cls: 0.3105  s2.acc: 96.6797  s2.loss_bbox: 0.0071  s2.loss_mask: 0.2323\n",
      "08/07 18:36:08 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:36:08 - mmengine - INFO - Saving checkpoint at 1 epochs\n",
      "08/07 18:36:15 - mmengine - INFO - Epoch(train)  [2][10/36]  lr: 2.2773e-04  eta: 0:20:26  time: 1.8205  data_time: 1.0920  memory: 4936  loss: 2.8531  loss_rpn_cls: 0.0483  loss_rpn_bbox: 0.0015  s0.loss_cls: 0.7906  s0.acc: 92.7734  s0.loss_bbox: 0.0105  s0.loss_mask: 0.6674  s1.loss_cls: 0.4778  s1.acc: 91.2109  s1.loss_bbox: 0.0135  s1.loss_mask: 0.3796  s2.loss_cls: 0.2384  s2.acc: 90.6250  s2.loss_bbox: 0.0091  s2.loss_mask: 0.2163\n",
      "08/07 18:36:19 - mmengine - INFO - Epoch(train)  [2][20/36]  lr: 2.7778e-04  eta: 0:17:14  time: 0.3621  data_time: 0.0262  memory: 4662  loss: 2.4380  loss_rpn_cls: 0.0462  loss_rpn_bbox: 0.0014  s0.loss_cls: 0.5842  s0.acc: 99.4141  s0.loss_bbox: 0.0094  s0.loss_mask: 0.6503  s1.loss_cls: 0.3638  s1.acc: 99.2188  s1.loss_bbox: 0.0137  s1.loss_mask: 0.3674  s2.loss_cls: 0.1874  s2.acc: 99.4141  s2.loss_bbox: 0.0097  s2.loss_mask: 0.2046\n",
      "08/07 18:36:22 - mmengine - INFO - Epoch(train)  [2][30/36]  lr: 3.2783e-04  eta: 0:14:58  time: 0.3667  data_time: 0.0284  memory: 4155  loss: 1.9702  loss_rpn_cls: 0.0457  loss_rpn_bbox: 0.0015  s0.loss_cls: 0.3539  s0.acc: 95.1172  s0.loss_bbox: 0.0087  s0.loss_mask: 0.6289  s1.loss_cls: 0.2329  s1.acc: 93.1641  s1.loss_bbox: 0.0150  s1.loss_mask: 0.3533  s2.loss_cls: 0.1280  s2.acc: 92.9688  s2.loss_bbox: 0.0113  s2.loss_mask: 0.1910\n",
      "08/07 18:36:25 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:36:25 - mmengine - INFO - Saving checkpoint at 2 epochs\n",
      "08/07 18:36:32 - mmengine - INFO - Epoch(train)  [3][10/36]  lr: 4.0791e-04  eta: 0:12:36  time: 0.3789  data_time: 0.0341  memory: 4952  loss: 1.5310  loss_rpn_cls: 0.0093  loss_rpn_bbox: 0.0011  s0.loss_cls: 0.1890  s0.acc: 93.9453  s0.loss_bbox: 0.0101  s0.loss_mask: 0.5734  s1.loss_cls: 0.1399  s1.acc: 92.9688  s1.loss_bbox: 0.0197  s1.loss_mask: 0.3223  s2.loss_cls: 0.0827  s2.acc: 92.7734  s2.loss_bbox: 0.0158  s2.loss_mask: 0.1677\n",
      "08/07 18:36:35 - mmengine - INFO - Epoch(train)  [3][20/36]  lr: 4.5796e-04  eta: 0:11:28  time: 0.3667  data_time: 0.0267  memory: 4556  loss: 1.4017  loss_rpn_cls: 0.0040  loss_rpn_bbox: 0.0008  s0.loss_cls: 0.1589  s0.acc: 95.7031  s0.loss_bbox: 0.0097  s0.loss_mask: 0.5362  s1.loss_cls: 0.1247  s1.acc: 92.9688  s1.loss_bbox: 0.0193  s1.loss_mask: 0.3005  s2.loss_cls: 0.0754  s2.acc: 93.5547  s2.loss_bbox: 0.0158  s2.loss_mask: 0.1564\n",
      "08/07 18:36:39 - mmengine - INFO - Epoch(train)  [3][30/36]  lr: 5.0801e-04  eta: 0:10:33  time: 0.3755  data_time: 0.0283  memory: 5057  loss: 1.3289  loss_rpn_cls: 0.0028  loss_rpn_bbox: 0.0011  s0.loss_cls: 0.1542  s0.acc: 95.8984  s0.loss_bbox: 0.0106  s0.loss_mask: 0.4985  s1.loss_cls: 0.1244  s1.acc: 92.7734  s1.loss_bbox: 0.0231  s1.loss_mask: 0.2753  s2.loss_cls: 0.0762  s2.acc: 91.9922  s2.loss_bbox: 0.0190  s2.loss_mask: 0.1435\n",
      "08/07 18:36:41 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:36:41 - mmengine - INFO - Saving checkpoint at 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ja683\\downloads\\saf\\mmdetection\\mmdet\\models\\roi_heads\\mask_heads\\fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  mask_preds = bboxes.new_tensor(mask_preds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/07 18:36:59 - mmengine - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.650\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.816\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.650\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.900\n",
      "08/07 18:37:00 - mmengine - INFO - bbox_mAP_copypaste: 0.045 0.068 0.045 0.029 0.650 0.816\n",
      "08/07 18:37:00 - mmengine - INFO - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.750\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.674\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.238\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.238\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.750\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.767\n",
      "08/07 18:37:00 - mmengine - INFO - segm_mAP_copypaste: 0.041 0.075 0.048 0.030 0.750 0.674\n",
      "08/07 18:37:00 - mmengine - INFO - Epoch(val) [3][8/8]    coco/bbox_mAP: 0.0450  coco/bbox_mAP_50: 0.0680  coco/bbox_mAP_75: 0.0450  coco/bbox_mAP_s: 0.0290  coco/bbox_mAP_m: 0.6500  coco/bbox_mAP_l: 0.8160  coco/segm_mAP: 0.0410  coco/segm_mAP_50: 0.0750  coco/segm_mAP_75: 0.0480  coco/segm_mAP_s: 0.0300  coco/segm_mAP_m: 0.7500  coco/segm_mAP_l: 0.6740  data_time: 1.1329  time: 1.8741\n",
      "08/07 18:37:02 - mmengine - INFO - The best checkpoint with 0.0450 coco/bbox_mAP at 3 epoch is saved to best_coco_bbox_mAP_epoch_3.pth.\n",
      "08/07 18:37:04 - mmengine - INFO - The best checkpoint with 0.0410 coco/segm_mAP at 3 epoch is saved to best_coco_segm_mAP_epoch_3.pth.\n",
      "08/07 18:37:11 - mmengine - INFO - Epoch(train)  [4][10/36]  lr: 5.8809e-04  eta: 0:09:27  time: 0.3947  data_time: 0.0357  memory: 4694  loss: 1.1870  loss_rpn_cls: 0.0016  loss_rpn_bbox: 0.0006  s0.loss_cls: 0.1449  s0.acc: 97.6562  s0.loss_bbox: 0.0108  s0.loss_mask: 0.4434  s1.loss_cls: 0.1141  s1.acc: 95.7031  s1.loss_bbox: 0.0250  s1.loss_mask: 0.2339  s2.loss_cls: 0.0724  s2.acc: 95.1172  s2.loss_bbox: 0.0209  s2.loss_mask: 0.1195\n",
      "08/07 18:37:15 - mmengine - INFO - Epoch(train)  [4][20/36]  lr: 6.3814e-04  eta: 0:08:51  time: 0.3797  data_time: 0.0281  memory: 5065  loss: 1.1112  loss_rpn_cls: 0.0015  loss_rpn_bbox: 0.0009  s0.loss_cls: 0.1354  s0.acc: 97.2656  s0.loss_bbox: 0.0113  s0.loss_mask: 0.4226  s1.loss_cls: 0.1045  s1.acc: 96.0938  s1.loss_bbox: 0.0270  s1.loss_mask: 0.2127  s2.loss_cls: 0.0663  s2.acc: 95.3125  s2.loss_bbox: 0.0220  s2.loss_mask: 0.1071\n",
      "08/07 18:37:18 - mmengine - INFO - Epoch(train)  [4][30/36]  lr: 6.8819e-04  eta: 0:08:19  time: 0.3803  data_time: 0.0274  memory: 4866  loss: 1.0414  loss_rpn_cls: 0.0013  loss_rpn_bbox: 0.0008  s0.loss_cls: 0.1291  s0.acc: 95.5078  s0.loss_bbox: 0.0119  s0.loss_mask: 0.3897  s1.loss_cls: 0.1009  s1.acc: 93.9453  s1.loss_bbox: 0.0320  s1.loss_mask: 0.1901  s2.loss_cls: 0.0648  s2.acc: 91.4062  s2.loss_bbox: 0.0265  s2.loss_mask: 0.0944\n",
      "08/07 18:37:21 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:37:21 - mmengine - INFO - Saving checkpoint at 4 epochs\n",
      "08/07 18:37:28 - mmengine - INFO - Epoch(train)  [5][10/36]  lr: 7.6827e-04  eta: 0:07:39  time: 0.3966  data_time: 0.0334  memory: 5070  loss: 0.9570  loss_rpn_cls: 0.0004  loss_rpn_bbox: 0.0007  s0.loss_cls: 0.1264  s0.acc: 94.3359  s0.loss_bbox: 0.0129  s0.loss_mask: 0.3514  s1.loss_cls: 0.0951  s1.acc: 90.2344  s1.loss_bbox: 0.0316  s1.loss_mask: 0.1665  s2.loss_cls: 0.0632  s2.acc: 88.8672  s2.loss_bbox: 0.0273  s2.loss_mask: 0.0815\n",
      "08/07 18:37:32 - mmengine - INFO - Epoch(train)  [5][20/36]  lr: 8.1832e-04  eta: 0:07:17  time: 0.3815  data_time: 0.0255  memory: 4757  loss: 0.9413  loss_rpn_cls: 0.0004  loss_rpn_bbox: 0.0006  s0.loss_cls: 0.1236  s0.acc: 92.5781  s0.loss_bbox: 0.0149  s0.loss_mask: 0.3393  s1.loss_cls: 0.0912  s1.acc: 91.6016  s1.loss_bbox: 0.0382  s1.loss_mask: 0.1626  s2.loss_cls: 0.0599  s2.acc: 90.8203  s2.loss_bbox: 0.0317  s2.loss_mask: 0.0790\n",
      "08/07 18:37:36 - mmengine - INFO - Epoch(train)  [5][30/36]  lr: 8.6837e-04  eta: 0:06:57  time: 0.3922  data_time: 0.0278  memory: 5069  loss: 0.9272  loss_rpn_cls: 0.0003  loss_rpn_bbox: 0.0005  s0.loss_cls: 0.1304  s0.acc: 94.1406  s0.loss_bbox: 0.0148  s0.loss_mask: 0.3227  s1.loss_cls: 0.0932  s1.acc: 92.9688  s1.loss_bbox: 0.0379  s1.loss_mask: 0.1565  s2.loss_cls: 0.0616  s2.acc: 85.5469  s2.loss_bbox: 0.0327  s2.loss_mask: 0.0767\n",
      "08/07 18:37:38 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:37:38 - mmengine - INFO - Saving checkpoint at 5 epochs\n",
      "08/07 18:37:46 - mmengine - INFO - Epoch(train)  [6][10/36]  lr: 9.4845e-04  eta: 0:06:29  time: 0.4096  data_time: 0.0380  memory: 5065  loss: 0.8915  loss_rpn_cls: 0.0005  loss_rpn_bbox: 0.0008  s0.loss_cls: 0.1241  s0.acc: 94.9219  s0.loss_bbox: 0.0152  s0.loss_mask: 0.3092  s1.loss_cls: 0.0890  s1.acc: 93.9453  s1.loss_bbox: 0.0365  s1.loss_mask: 0.1503  s2.loss_cls: 0.0592  s2.acc: 92.7734  s2.loss_bbox: 0.0324  s2.loss_mask: 0.0744\n",
      "08/07 18:37:49 - mmengine - INFO - Epoch(train)  [6][20/36]  lr: 9.9850e-04  eta: 0:06:13  time: 0.3974  data_time: 0.0317  memory: 5062  loss: 0.8681  loss_rpn_cls: 0.0007  loss_rpn_bbox: 0.0007  s0.loss_cls: 0.1157  s0.acc: 96.0938  s0.loss_bbox: 0.0139  s0.loss_mask: 0.3062  s1.loss_cls: 0.0842  s1.acc: 95.1172  s1.loss_bbox: 0.0338  s1.loss_mask: 0.1502  s2.loss_cls: 0.0567  s2.acc: 93.3594  s2.loss_bbox: 0.0317  s2.loss_mask: 0.0743\n",
      "08/07 18:37:53 - mmengine - INFO - Epoch(train)  [6][30/36]  lr: 1.0485e-03  eta: 0:05:57  time: 0.3988  data_time: 0.0315  memory: 4465  loss: 0.8414  loss_rpn_cls: 0.0008  loss_rpn_bbox: 0.0008  s0.loss_cls: 0.1124  s0.acc: 99.0234  s0.loss_bbox: 0.0127  s0.loss_mask: 0.3012  s1.loss_cls: 0.0803  s1.acc: 96.8750  s1.loss_bbox: 0.0285  s1.loss_mask: 0.1480  s2.loss_cls: 0.0547  s2.acc: 96.8750  s2.loss_bbox: 0.0284  s2.loss_mask: 0.0736\n",
      "08/07 18:37:55 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:37:55 - mmengine - INFO - Saving checkpoint at 6 epochs\n",
      "08/07 18:38:06 - mmengine - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.13s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.303\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.413\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.911\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.850\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.933\n",
      "08/07 18:38:06 - mmengine - INFO - bbox_mAP_copypaste: 0.256 0.303 0.277 0.042 0.413 0.911\n",
      "08/07 18:38:06 - mmengine - INFO - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.285\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.800\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.834\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.833\n",
      "08/07 18:38:06 - mmengine - INFO - segm_mAP_copypaste: 0.241 0.310 0.285 0.046 0.800 0.834\n",
      "08/07 18:38:06 - mmengine - INFO - Epoch(val) [6][8/8]    coco/bbox_mAP: 0.2560  coco/bbox_mAP_50: 0.3030  coco/bbox_mAP_75: 0.2770  coco/bbox_mAP_s: 0.0420  coco/bbox_mAP_m: 0.4130  coco/bbox_mAP_l: 0.9110  coco/segm_mAP: 0.2410  coco/segm_mAP_50: 0.3100  coco/segm_mAP_75: 0.2850  coco/segm_mAP_s: 0.0460  coco/segm_mAP_m: 0.8000  coco/segm_mAP_l: 0.8340  data_time: 0.1953  time: 0.9309\n",
      "08/07 18:38:06 - mmengine - INFO - The previous best checkpoint C:\\Users\\ja683\\Downloads\\saf\\tutorial_exps\\20-epochs-benchmark\\best_coco_bbox_mAP_epoch_3.pth is removed\n",
      "08/07 18:38:08 - mmengine - INFO - The best checkpoint with 0.2560 coco/bbox_mAP at 6 epoch is saved to best_coco_bbox_mAP_epoch_6.pth.\n",
      "08/07 18:38:08 - mmengine - INFO - The previous best checkpoint C:\\Users\\ja683\\Downloads\\saf\\tutorial_exps\\20-epochs-benchmark\\best_coco_segm_mAP_epoch_3.pth is removed\n",
      "08/07 18:38:10 - mmengine - INFO - The best checkpoint with 0.2410 coco/segm_mAP at 6 epoch is saved to best_coco_segm_mAP_epoch_6.pth.\n",
      "08/07 18:38:18 - mmengine - INFO - Epoch(train)  [7][10/36]  lr: 1.1286e-03  eta: 0:05:36  time: 0.4047  data_time: 0.0341  memory: 5070  loss: 0.7867  loss_rpn_cls: 0.0007  loss_rpn_bbox: 0.0011  s0.loss_cls: 0.0937  s0.acc: 96.2891  s0.loss_bbox: 0.0118  s0.loss_mask: 0.2935  s1.loss_cls: 0.0704  s1.acc: 93.9453  s1.loss_bbox: 0.0260  s1.loss_mask: 0.1426  s2.loss_cls: 0.0495  s2.acc: 94.3359  s2.loss_bbox: 0.0276  s2.loss_mask: 0.0698\n",
      "08/07 18:38:21 - mmengine - INFO - Epoch(train)  [7][20/36]  lr: 1.1787e-03  eta: 0:05:23  time: 0.3894  data_time: 0.0255  memory: 4754  loss: 0.7646  loss_rpn_cls: 0.0006  loss_rpn_bbox: 0.0008  s0.loss_cls: 0.0870  s0.acc: 97.4609  s0.loss_bbox: 0.0103  s0.loss_mask: 0.2902  s1.loss_cls: 0.0663  s1.acc: 95.5078  s1.loss_bbox: 0.0248  s1.loss_mask: 0.1416  s2.loss_cls: 0.0471  s2.acc: 91.9922  s2.loss_bbox: 0.0267  s2.loss_mask: 0.0691\n",
      "08/07 18:38:25 - mmengine - INFO - Epoch(train)  [7][30/36]  lr: 1.2287e-03  eta: 0:05:11  time: 0.3877  data_time: 0.0251  memory: 5070  loss: 0.7521  loss_rpn_cls: 0.0009  loss_rpn_bbox: 0.0009  s0.loss_cls: 0.0836  s0.acc: 96.2891  s0.loss_bbox: 0.0098  s0.loss_mask: 0.2867  s1.loss_cls: 0.0635  s1.acc: 96.2891  s1.loss_bbox: 0.0254  s1.loss_mask: 0.1403  s2.loss_cls: 0.0454  s2.acc: 94.5312  s2.loss_bbox: 0.0269  s2.loss_mask: 0.0685\n",
      "08/07 18:38:27 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:38:27 - mmengine - INFO - Saving checkpoint at 7 epochs\n",
      "08/07 18:38:35 - mmengine - INFO - Epoch(train)  [8][10/36]  lr: 1.3088e-03  eta: 0:04:53  time: 0.3969  data_time: 0.0302  memory: 4720  loss: 0.7177  loss_rpn_cls: 0.0009  loss_rpn_bbox: 0.0010  s0.loss_cls: 0.0816  s0.acc: 97.4609  s0.loss_bbox: 0.0100  s0.loss_mask: 0.2696  s1.loss_cls: 0.0617  s1.acc: 99.2188  s1.loss_bbox: 0.0261  s1.loss_mask: 0.1312  s2.loss_cls: 0.0439  s2.acc: 99.4141  s2.loss_bbox: 0.0275  s2.loss_mask: 0.0641\n",
      "08/07 18:38:38 - mmengine - INFO - Epoch(train)  [8][20/36]  lr: 1.3589e-03  eta: 0:04:42  time: 0.3840  data_time: 0.0264  memory: 5070  loss: 0.7170  loss_rpn_cls: 0.0010  loss_rpn_bbox: 0.0006  s0.loss_cls: 0.0790  s0.acc: 99.8047  s0.loss_bbox: 0.0090  s0.loss_mask: 0.2748  s1.loss_cls: 0.0601  s1.acc: 98.4375  s1.loss_bbox: 0.0253  s1.loss_mask: 0.1328  s2.loss_cls: 0.0424  s2.acc: 96.2891  s2.loss_bbox: 0.0269  s2.loss_mask: 0.0650\n",
      "08/07 18:38:42 - mmengine - INFO - Epoch(train)  [8][30/36]  lr: 1.4089e-03  eta: 0:04:32  time: 0.3863  data_time: 0.0269  memory: 5070  loss: 0.6961  loss_rpn_cls: 0.0009  loss_rpn_bbox: 0.0006  s0.loss_cls: 0.0752  s0.acc: 99.0234  s0.loss_bbox: 0.0080  s0.loss_mask: 0.2726  s1.loss_cls: 0.0549  s1.acc: 98.2422  s1.loss_bbox: 0.0221  s1.loss_mask: 0.1327  s2.loss_cls: 0.0393  s2.acc: 93.9453  s2.loss_bbox: 0.0247  s2.loss_mask: 0.0650\n",
      "08/07 18:38:44 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:38:44 - mmengine - INFO - Saving checkpoint at 8 epochs\n",
      "08/07 18:38:52 - mmengine - INFO - Epoch(train)  [9][10/36]  lr: 1.4890e-03  eta: 0:04:17  time: 0.3926  data_time: 0.0314  memory: 5061  loss: 0.6722  loss_rpn_cls: 0.0004  loss_rpn_bbox: 0.0007  s0.loss_cls: 0.0715  s0.acc: 99.8047  s0.loss_bbox: 0.0090  s0.loss_mask: 0.2624  s1.loss_cls: 0.0515  s1.acc: 99.6094  s1.loss_bbox: 0.0228  s1.loss_mask: 0.1278  s2.loss_cls: 0.0374  s2.acc: 99.4141  s2.loss_bbox: 0.0259  s2.loss_mask: 0.0628\n",
      "08/07 18:38:56 - mmengine - INFO - Epoch(train)  [9][20/36]  lr: 1.5390e-03  eta: 0:04:09  time: 0.3951  data_time: 0.0290  memory: 5069  loss: 0.6823  loss_rpn_cls: 0.0004  loss_rpn_bbox: 0.0006  s0.loss_cls: 0.0697  s0.acc: 97.2656  s0.loss_bbox: 0.0091  s0.loss_mask: 0.2699  s1.loss_cls: 0.0494  s1.acc: 98.4375  s1.loss_bbox: 0.0228  s1.loss_mask: 0.1325  s2.loss_cls: 0.0360  s2.acc: 97.6562  s2.loss_bbox: 0.0265  s2.loss_mask: 0.0655\n",
      "08/07 18:39:00 - mmengine - INFO - Epoch(train)  [9][30/36]  lr: 1.5891e-03  eta: 0:04:00  time: 0.3908  data_time: 0.0281  memory: 4897  loss: 0.6735  loss_rpn_cls: 0.0003  loss_rpn_bbox: 0.0005  s0.loss_cls: 0.0636  s0.acc: 96.6797  s0.loss_bbox: 0.0094  s0.loss_mask: 0.2714  s1.loss_cls: 0.0454  s1.acc: 92.9688  s1.loss_bbox: 0.0228  s1.loss_mask: 0.1337  s2.loss_cls: 0.0335  s2.acc: 90.0391  s2.loss_bbox: 0.0265  s2.loss_mask: 0.0663\n",
      "08/07 18:39:02 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:39:02 - mmengine - INFO - Saving checkpoint at 9 epochs\n",
      "08/07 18:39:12 - mmengine - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.13s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.307\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.038\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.866\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.091\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.867\n",
      "08/07 18:39:13 - mmengine - INFO - bbox_mAP_copypaste: 0.246 0.307 0.277 0.038 0.900 0.866\n",
      "08/07 18:39:13 - mmengine - INFO - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.15s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.850\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.817\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.850\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.833\n",
      "08/07 18:39:13 - mmengine - INFO - segm_mAP_copypaste: 0.238 0.320 0.282 0.044 0.850 0.817\n",
      "08/07 18:39:13 - mmengine - INFO - Epoch(val) [9][8/8]    coco/bbox_mAP: 0.2460  coco/bbox_mAP_50: 0.3070  coco/bbox_mAP_75: 0.2770  coco/bbox_mAP_s: 0.0380  coco/bbox_mAP_m: 0.9000  coco/bbox_mAP_l: 0.8660  coco/segm_mAP: 0.2380  coco/segm_mAP_50: 0.3200  coco/segm_mAP_75: 0.2820  coco/segm_mAP_s: 0.0440  coco/segm_mAP_m: 0.8500  coco/segm_mAP_l: 0.8170  data_time: 0.1909  time: 0.9206\n",
      "08/07 18:39:17 - mmengine - INFO - Epoch(train) [10][10/36]  lr: 1.6692e-03  eta: 0:03:47  time: 0.4056  data_time: 0.0401  memory: 5062  loss: 0.6563  loss_rpn_cls: 0.0003  loss_rpn_bbox: 0.0005  s0.loss_cls: 0.0664  s0.acc: 97.6562  s0.loss_bbox: 0.0098  s0.loss_mask: 0.2570  s1.loss_cls: 0.0466  s1.acc: 96.8689  s1.loss_bbox: 0.0243  s1.loss_mask: 0.1279  s2.loss_cls: 0.0334  s2.acc: 96.4215  s2.loss_bbox: 0.0265  s2.loss_mask: 0.0635\n",
      "08/07 18:39:21 - mmengine - INFO - Epoch(train) [10][20/36]  lr: 1.7192e-03  eta: 0:03:38  time: 0.3879  data_time: 0.0323  memory: 4754  loss: 0.6511  loss_rpn_cls: 0.0005  loss_rpn_bbox: 0.0003  s0.loss_cls: 0.0612  s0.acc: 99.2188  s0.loss_bbox: 0.0091  s0.loss_mask: 0.2596  s1.loss_cls: 0.0447  s1.acc: 96.6797  s1.loss_bbox: 0.0230  s1.loss_mask: 0.1295  s2.loss_cls: 0.0322  s2.acc: 95.3125  s2.loss_bbox: 0.0266  s2.loss_mask: 0.0644\n",
      "08/07 18:39:25 - mmengine - INFO - Epoch(train) [10][30/36]  lr: 1.7693e-03  eta: 0:03:30  time: 0.3847  data_time: 0.0316  memory: 4243  loss: 0.6377  loss_rpn_cls: 0.0005  loss_rpn_bbox: 0.0004  s0.loss_cls: 0.0612  s0.acc: 96.8750  s0.loss_bbox: 0.0089  s0.loss_mask: 0.2542  s1.loss_cls: 0.0441  s1.acc: 94.9219  s1.loss_bbox: 0.0225  s1.loss_mask: 0.1258  s2.loss_cls: 0.0321  s2.acc: 91.0156  s2.loss_bbox: 0.0256  s2.loss_mask: 0.0623\n",
      "08/07 18:39:27 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:39:27 - mmengine - INFO - Saving checkpoint at 10 epochs\n",
      "08/07 18:39:34 - mmengine - INFO - Epoch(train) [11][10/36]  lr: 1.8493e-03  eta: 0:03:19  time: 0.3960  data_time: 0.0384  memory: 5062  loss: 0.6391  loss_rpn_cls: 0.0007  loss_rpn_bbox: 0.0006  s0.loss_cls: 0.0593  s0.acc: 98.8281  s0.loss_bbox: 0.0097  s0.loss_mask: 0.2528  s1.loss_cls: 0.0438  s1.acc: 99.6094  s1.loss_bbox: 0.0251  s1.loss_mask: 0.1260  s2.loss_cls: 0.0311  s2.acc: 99.8047  s2.loss_bbox: 0.0275  s2.loss_mask: 0.0625\n",
      "08/07 18:39:38 - mmengine - INFO - Epoch(train) [11][20/36]  lr: 1.8994e-03  eta: 0:03:11  time: 0.3909  data_time: 0.0279  memory: 5059  loss: 0.6420  loss_rpn_cls: 0.0008  loss_rpn_bbox: 0.0007  s0.loss_cls: 0.0574  s0.acc: 98.2422  s0.loss_bbox: 0.0101  s0.loss_mask: 0.2588  s1.loss_cls: 0.0415  s1.acc: 95.7031  s1.loss_bbox: 0.0237  s1.loss_mask: 0.1286  s2.loss_cls: 0.0296  s2.acc: 94.9219  s2.loss_bbox: 0.0267  s2.loss_mask: 0.0641\n",
      "08/07 18:39:42 - mmengine - INFO - Epoch(train) [11][30/36]  lr: 1.9494e-03  eta: 0:03:04  time: 0.3971  data_time: 0.0293  memory: 5001  loss: 0.6454  loss_rpn_cls: 0.0008  loss_rpn_bbox: 0.0006  s0.loss_cls: 0.0605  s0.acc: 95.5078  s0.loss_bbox: 0.0108  s0.loss_mask: 0.2563  s1.loss_cls: 0.0435  s1.acc: 93.5547  s1.loss_bbox: 0.0256  s1.loss_mask: 0.1260  s2.loss_cls: 0.0310  s2.acc: 91.9922  s2.loss_bbox: 0.0276  s2.loss_mask: 0.0626\n",
      "08/07 18:39:44 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:39:44 - mmengine - INFO - Saving checkpoint at 11 epochs\n",
      "08/07 18:39:53 - mmengine - INFO - Epoch(train) [12][10/36]  lr: 2.0295e-03  eta: 0:02:54  time: 0.4231  data_time: 0.0455  memory: 5068  loss: 0.6432  loss_rpn_cls: 0.0010  loss_rpn_bbox: 0.0005  s0.loss_cls: 0.0617  s0.acc: 99.0234  s0.loss_bbox: 0.0109  s0.loss_mask: 0.2541  s1.loss_cls: 0.0429  s1.acc: 99.4141  s1.loss_bbox: 0.0260  s1.loss_mask: 0.1256  s2.loss_cls: 0.0298  s2.acc: 96.8750  s2.loss_bbox: 0.0286  s2.loss_mask: 0.0623\n",
      "08/07 18:39:56 - mmengine - INFO - Epoch(train) [12][20/36]  lr: 2.0796e-03  eta: 0:02:47  time: 0.4115  data_time: 0.0377  memory: 5061  loss: 0.6286  loss_rpn_cls: 0.0010  loss_rpn_bbox: 0.0007  s0.loss_cls: 0.0595  s0.acc: 97.2656  s0.loss_bbox: 0.0112  s0.loss_mask: 0.2500  s1.loss_cls: 0.0407  s1.acc: 96.5932  s1.loss_bbox: 0.0251  s1.loss_mask: 0.1231  s2.loss_cls: 0.0283  s2.acc: 95.1020  s2.loss_bbox: 0.0282  s2.loss_mask: 0.0609\n",
      "08/07 18:40:00 - mmengine - INFO - Epoch(train) [12][30/36]  lr: 2.1296e-03  eta: 0:02:40  time: 0.4031  data_time: 0.0351  memory: 4631  loss: 0.6223  loss_rpn_cls: 0.0008  loss_rpn_bbox: 0.0010  s0.loss_cls: 0.0578  s0.acc: 99.2188  s0.loss_bbox: 0.0102  s0.loss_mask: 0.2466  s1.loss_cls: 0.0406  s1.acc: 99.2188  s1.loss_bbox: 0.0262  s1.loss_mask: 0.1213  s2.loss_cls: 0.0287  s2.acc: 99.2188  s2.loss_bbox: 0.0291  s2.loss_mask: 0.0601\n",
      "08/07 18:40:02 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:40:02 - mmengine - INFO - Saving checkpoint at 12 epochs\n",
      "08/07 18:40:12 - mmengine - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.285\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.800\n",
      "08/07 18:40:13 - mmengine - INFO - bbox_mAP_copypaste: 0.239 0.319 0.285 0.050 0.900 0.800\n",
      "08/07 18:40:13 - mmengine - INFO - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.327\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.301\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.058\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.850\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.850\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.800\n",
      "08/07 18:40:13 - mmengine - INFO - segm_mAP_copypaste: 0.245 0.327 0.301 0.058 0.850 0.800\n",
      "08/07 18:40:13 - mmengine - INFO - Epoch(val) [12][8/8]    coco/bbox_mAP: 0.2390  coco/bbox_mAP_50: 0.3190  coco/bbox_mAP_75: 0.2850  coco/bbox_mAP_s: 0.0500  coco/bbox_mAP_m: 0.9000  coco/bbox_mAP_l: 0.8000  coco/segm_mAP: 0.2450  coco/segm_mAP_50: 0.3270  coco/segm_mAP_75: 0.3010  coco/segm_mAP_s: 0.0580  coco/segm_mAP_m: 0.8500  coco/segm_mAP_l: 0.8000  data_time: 0.2074  time: 0.8855\n",
      "08/07 18:40:13 - mmengine - INFO - The previous best checkpoint C:\\Users\\ja683\\Downloads\\saf\\tutorial_exps\\20-epochs-benchmark\\best_coco_segm_mAP_epoch_6.pth is removed\n",
      "08/07 18:40:15 - mmengine - INFO - The best checkpoint with 0.2450 coco/segm_mAP at 12 epoch is saved to best_coco_segm_mAP_epoch_12.pth.\n",
      "08/07 18:40:22 - mmengine - INFO - Epoch(train) [13][10/36]  lr: 2.2097e-03  eta: 0:02:30  time: 0.4002  data_time: 0.0381  memory: 4450  loss: 0.5925  loss_rpn_cls: 0.0004  loss_rpn_bbox: 0.0010  s0.loss_cls: 0.0499  s0.acc: 98.0469  s0.loss_bbox: 0.0080  s0.loss_mask: 0.2464  s1.loss_cls: 0.0343  s1.acc: 94.5312  s1.loss_bbox: 0.0207  s1.loss_mask: 0.1218  s2.loss_cls: 0.0243  s2.acc: 92.1875  s2.loss_bbox: 0.0251  s2.loss_mask: 0.0607\n",
      "08/07 18:40:25 - mmengine - INFO - Epoch(train) [13][20/36]  lr: 2.2598e-03  eta: 0:02:23  time: 0.3691  data_time: 0.0209  memory: 4345  loss: 0.5856  loss_rpn_cls: 0.0005  loss_rpn_bbox: 0.0012  s0.loss_cls: 0.0427  s0.acc: 99.2188  s0.loss_bbox: 0.0069  s0.loss_mask: 0.2530  s1.loss_cls: 0.0311  s1.acc: 98.6328  s1.loss_bbox: 0.0184  s1.loss_mask: 0.1247  s2.loss_cls: 0.0226  s2.acc: 97.6562  s2.loss_bbox: 0.0222  s2.loss_mask: 0.0624\n",
      "08/07 18:40:29 - mmengine - INFO - Epoch(train) [13][30/36]  lr: 2.3098e-03  eta: 0:02:17  time: 0.3770  data_time: 0.0238  memory: 5070  loss: 0.5932  loss_rpn_cls: 0.0005  loss_rpn_bbox: 0.0012  s0.loss_cls: 0.0430  s0.acc: 99.0234  s0.loss_bbox: 0.0075  s0.loss_mask: 0.2567  s1.loss_cls: 0.0296  s1.acc: 99.4141  s1.loss_bbox: 0.0188  s1.loss_mask: 0.1276  s2.loss_cls: 0.0218  s2.acc: 98.8281  s2.loss_bbox: 0.0221  s2.loss_mask: 0.0642\n",
      "08/07 18:40:32 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:40:32 - mmengine - INFO - Saving checkpoint at 13 epochs\n",
      "08/07 18:40:40 - mmengine - INFO - Epoch(train) [14][10/36]  lr: 2.3899e-03  eta: 0:02:08  time: 0.4097  data_time: 0.0437  memory: 5070  loss: 0.6025  loss_rpn_cls: 0.0005  loss_rpn_bbox: 0.0010  s0.loss_cls: 0.0415  s0.acc: 98.8281  s0.loss_bbox: 0.0081  s0.loss_mask: 0.2639  s1.loss_cls: 0.0279  s1.acc: 98.6328  s1.loss_bbox: 0.0198  s1.loss_mask: 0.1308  s2.loss_cls: 0.0209  s2.acc: 97.8516  s2.loss_bbox: 0.0228  s2.loss_mask: 0.0655\n",
      "08/07 18:40:44 - mmengine - INFO - Epoch(train) [14][20/36]  lr: 2.4399e-03  eta: 0:02:02  time: 0.4081  data_time: 0.0408  memory: 5062  loss: 0.6089  loss_rpn_cls: 0.0005  loss_rpn_bbox: 0.0014  s0.loss_cls: 0.0422  s0.acc: 98.6328  s0.loss_bbox: 0.0107  s0.loss_mask: 0.2613  s1.loss_cls: 0.0275  s1.acc: 99.4141  s1.loss_bbox: 0.0228  s1.loss_mask: 0.1306  s2.loss_cls: 0.0212  s2.acc: 99.2188  s2.loss_bbox: 0.0254  s2.loss_mask: 0.0654\n",
      "08/07 18:40:47 - mmengine - INFO - Epoch(train) [14][30/36]  lr: 2.4900e-03  eta: 0:01:56  time: 0.4111  data_time: 0.0411  memory: 5068  loss: 0.5961  loss_rpn_cls: 0.0005  loss_rpn_bbox: 0.0016  s0.loss_cls: 0.0423  s0.acc: 98.2422  s0.loss_bbox: 0.0125  s0.loss_mask: 0.2512  s1.loss_cls: 0.0265  s1.acc: 98.4375  s1.loss_bbox: 0.0247  s1.loss_mask: 0.1260  s2.loss_cls: 0.0204  s2.acc: 97.6562  s2.loss_bbox: 0.0270  s2.loss_mask: 0.0633\n",
      "08/07 18:40:49 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:40:49 - mmengine - INFO - Saving checkpoint at 14 epochs\n",
      "08/07 18:40:58 - mmengine - INFO - Epoch(train) [15][10/36]  lr: 2.5000e-03  eta: 0:01:47  time: 0.4278  data_time: 0.0530  memory: 5069  loss: 0.5709  loss_rpn_cls: 0.0004  loss_rpn_bbox: 0.0012  s0.loss_cls: 0.0400  s0.acc: 99.6094  s0.loss_bbox: 0.0117  s0.loss_mask: 0.2410  s1.loss_cls: 0.0254  s1.acc: 99.0234  s1.loss_bbox: 0.0233  s1.loss_mask: 0.1213  s2.loss_cls: 0.0199  s2.acc: 98.4375  s2.loss_bbox: 0.0261  s2.loss_mask: 0.0605\n",
      "08/07 18:41:01 - mmengine - INFO - Epoch(train) [15][20/36]  lr: 2.5000e-03  eta: 0:01:41  time: 0.3937  data_time: 0.0338  memory: 4664  loss: 0.5562  loss_rpn_cls: 0.0004  loss_rpn_bbox: 0.0012  s0.loss_cls: 0.0379  s0.acc: 97.6562  s0.loss_bbox: 0.0110  s0.loss_mask: 0.2373  s1.loss_cls: 0.0245  s1.acc: 96.6797  s1.loss_bbox: 0.0209  s1.loss_mask: 0.1199  s2.loss_cls: 0.0193  s2.acc: 94.7266  s2.loss_bbox: 0.0239  s2.loss_mask: 0.0598\n",
      "08/07 18:41:05 - mmengine - INFO - Epoch(train) [15][30/36]  lr: 2.5000e-03  eta: 0:01:36  time: 0.3906  data_time: 0.0337  memory: 4478  loss: 0.5329  loss_rpn_cls: 0.0004  loss_rpn_bbox: 0.0008  s0.loss_cls: 0.0352  s0.acc: 98.4375  s0.loss_bbox: 0.0091  s0.loss_mask: 0.2314  s1.loss_cls: 0.0232  s1.acc: 97.6562  s1.loss_bbox: 0.0168  s1.loss_mask: 0.1178  s2.loss_cls: 0.0176  s2.acc: 96.6797  s2.loss_bbox: 0.0219  s2.loss_mask: 0.0588\n",
      "08/07 18:41:07 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:41:07 - mmengine - INFO - Saving checkpoint at 15 epochs\n",
      "08/07 18:41:17 - mmengine - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.324\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.301\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.866\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.134\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.867\n",
      "08/07 18:41:17 - mmengine - INFO - bbox_mAP_copypaste: 0.264 0.324 0.301 0.064 0.900 0.866\n",
      "08/07 18:41:17 - mmengine - INFO - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.303\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.850\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.866\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.850\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.867\n",
      "08/07 18:41:17 - mmengine - INFO - segm_mAP_copypaste: 0.264 0.329 0.303 0.064 0.850 0.866\n",
      "08/07 18:41:17 - mmengine - INFO - Epoch(val) [15][8/8]    coco/bbox_mAP: 0.2640  coco/bbox_mAP_50: 0.3240  coco/bbox_mAP_75: 0.3010  coco/bbox_mAP_s: 0.0640  coco/bbox_mAP_m: 0.9000  coco/bbox_mAP_l: 0.8660  coco/segm_mAP: 0.2640  coco/segm_mAP_50: 0.3290  coco/segm_mAP_75: 0.3030  coco/segm_mAP_s: 0.0640  coco/segm_mAP_m: 0.8500  coco/segm_mAP_l: 0.8660  data_time: 0.2832  time: 0.7880\n",
      "08/07 18:41:17 - mmengine - INFO - The previous best checkpoint C:\\Users\\ja683\\Downloads\\saf\\tutorial_exps\\20-epochs-benchmark\\best_coco_bbox_mAP_epoch_6.pth is removed\n",
      "08/07 18:41:19 - mmengine - INFO - The best checkpoint with 0.2640 coco/bbox_mAP at 15 epoch is saved to best_coco_bbox_mAP_epoch_15.pth.\n",
      "08/07 18:41:19 - mmengine - INFO - The previous best checkpoint C:\\Users\\ja683\\Downloads\\saf\\tutorial_exps\\20-epochs-benchmark\\best_coco_segm_mAP_epoch_12.pth is removed\n",
      "08/07 18:41:21 - mmengine - INFO - The best checkpoint with 0.2640 coco/segm_mAP at 15 epoch is saved to best_coco_segm_mAP_epoch_15.pth.\n",
      "08/07 18:41:28 - mmengine - INFO - Epoch(train) [16][10/36]  lr: 2.5000e-03  eta: 0:01:27  time: 0.4074  data_time: 0.0422  memory: 5062  loss: 0.5200  loss_rpn_cls: 0.0004  loss_rpn_bbox: 0.0008  s0.loss_cls: 0.0356  s0.acc: 98.8281  s0.loss_bbox: 0.0068  s0.loss_mask: 0.2280  s1.loss_cls: 0.0239  s1.acc: 98.2422  s1.loss_bbox: 0.0147  s1.loss_mask: 0.1153  s2.loss_cls: 0.0173  s2.acc: 98.2422  s2.loss_bbox: 0.0203  s2.loss_mask: 0.0568\n",
      "08/07 18:41:32 - mmengine - INFO - Epoch(train) [16][20/36]  lr: 2.5000e-03  eta: 0:01:21  time: 0.3845  data_time: 0.0286  memory: 4828  loss: 0.5116  loss_rpn_cls: 0.0002  loss_rpn_bbox: 0.0009  s0.loss_cls: 0.0347  s0.acc: 99.0234  s0.loss_bbox: 0.0065  s0.loss_mask: 0.2246  s1.loss_cls: 0.0235  s1.acc: 98.2422  s1.loss_bbox: 0.0143  s1.loss_mask: 0.1133  s2.loss_cls: 0.0174  s2.acc: 97.0703  s2.loss_bbox: 0.0205  s2.loss_mask: 0.0557\n",
      "08/07 18:41:36 - mmengine - INFO - Epoch(train) [16][30/36]  lr: 2.5000e-03  eta: 0:01:16  time: 0.3807  data_time: 0.0273  memory: 4751  loss: 0.5003  loss_rpn_cls: 0.0002  loss_rpn_bbox: 0.0009  s0.loss_cls: 0.0326  s0.acc: 99.4141  s0.loss_bbox: 0.0059  s0.loss_mask: 0.2201  s1.loss_cls: 0.0230  s1.acc: 98.8281  s1.loss_bbox: 0.0139  s1.loss_mask: 0.1107  s2.loss_cls: 0.0174  s2.acc: 98.8281  s2.loss_bbox: 0.0212  s2.loss_mask: 0.0544\n",
      "08/07 18:41:38 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:41:38 - mmengine - INFO - Saving checkpoint at 16 epochs\n",
      "08/07 18:41:46 - mmengine - INFO - Epoch(train) [17][10/36]  lr: 2.5000e-04  eta: 0:01:07  time: 0.4094  data_time: 0.0403  memory: 5070  loss: 0.5041  loss_rpn_cls: 0.0002  loss_rpn_bbox: 0.0008  s0.loss_cls: 0.0331  s0.acc: 99.2188  s0.loss_bbox: 0.0063  s0.loss_mask: 0.2230  s1.loss_cls: 0.0224  s1.acc: 99.2188  s1.loss_bbox: 0.0151  s1.loss_mask: 0.1103  s2.loss_cls: 0.0174  s2.acc: 97.8516  s2.loss_bbox: 0.0208  s2.loss_mask: 0.0545\n",
      "08/07 18:41:49 - mmengine - INFO - Epoch(train) [17][20/36]  lr: 2.5000e-04  eta: 0:01:02  time: 0.3911  data_time: 0.0310  memory: 4707  loss: 0.4842  loss_rpn_cls: 0.0003  loss_rpn_bbox: 0.0007  s0.loss_cls: 0.0283  s0.acc: 100.0000  s0.loss_bbox: 0.0057  s0.loss_mask: 0.2177  s1.loss_cls: 0.0194  s1.acc: 99.8047  s1.loss_bbox: 0.0150  s1.loss_mask: 0.1073  s2.loss_cls: 0.0159  s2.acc: 99.8047  s2.loss_bbox: 0.0208  s2.loss_mask: 0.0532\n",
      "08/07 18:41:53 - mmengine - INFO - Epoch(train) [17][30/36]  lr: 2.5000e-04  eta: 0:00:57  time: 0.3922  data_time: 0.0311  memory: 5061  loss: 0.4619  loss_rpn_cls: 0.0004  loss_rpn_bbox: 0.0007  s0.loss_cls: 0.0278  s0.acc: 99.0234  s0.loss_bbox: 0.0053  s0.loss_mask: 0.2066  s1.loss_cls: 0.0190  s1.acc: 98.8281  s1.loss_bbox: 0.0143  s1.loss_mask: 0.1014  s2.loss_cls: 0.0158  s2.acc: 97.6562  s2.loss_bbox: 0.0203  s2.loss_mask: 0.0503\n",
      "08/07 18:41:56 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:41:56 - mmengine - INFO - Saving checkpoint at 17 epochs\n",
      "08/07 18:42:03 - mmengine - INFO - Epoch(train) [18][10/36]  lr: 2.5000e-04  eta: 0:00:49  time: 0.4099  data_time: 0.0400  memory: 5061  loss: 0.4496  loss_rpn_cls: 0.0005  loss_rpn_bbox: 0.0004  s0.loss_cls: 0.0261  s0.acc: 97.4609  s0.loss_bbox: 0.0047  s0.loss_mask: 0.2045  s1.loss_cls: 0.0175  s1.acc: 96.8750  s1.loss_bbox: 0.0131  s1.loss_mask: 0.1007  s2.loss_cls: 0.0144  s2.acc: 94.3359  s2.loss_bbox: 0.0177  s2.loss_mask: 0.0500\n",
      "08/07 18:42:07 - mmengine - INFO - Epoch(train) [18][20/36]  lr: 2.5000e-04  eta: 0:00:43  time: 0.3945  data_time: 0.0296  memory: 5020  loss: 0.4384  loss_rpn_cls: 0.0005  loss_rpn_bbox: 0.0003  s0.loss_cls: 0.0231  s0.acc: 97.8516  s0.loss_bbox: 0.0034  s0.loss_mask: 0.2028  s1.loss_cls: 0.0160  s1.acc: 96.4844  s1.loss_bbox: 0.0115  s1.loss_mask: 0.1007  s2.loss_cls: 0.0138  s2.acc: 93.9453  s2.loss_bbox: 0.0168  s2.loss_mask: 0.0496\n",
      "08/07 18:42:11 - mmengine - INFO - Epoch(train) [18][30/36]  lr: 2.5000e-04  eta: 0:00:38  time: 0.3964  data_time: 0.0301  memory: 4875  loss: 0.4232  loss_rpn_cls: 0.0007  loss_rpn_bbox: 0.0004  s0.loss_cls: 0.0226  s0.acc: 99.4141  s0.loss_bbox: 0.0030  s0.loss_mask: 0.1962  s1.loss_cls: 0.0154  s1.acc: 99.4141  s1.loss_bbox: 0.0100  s1.loss_mask: 0.0979  s2.loss_cls: 0.0131  s2.acc: 100.0000  s2.loss_bbox: 0.0156  s2.loss_mask: 0.0482\n",
      "08/07 18:42:13 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:42:13 - mmengine - INFO - Saving checkpoint at 18 epochs\n",
      "08/07 18:42:23 - mmengine - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.11s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.336\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.317\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.900\n",
      "08/07 18:42:23 - mmengine - INFO - bbox_mAP_copypaste: 0.279 0.336 0.317 0.072 0.900 0.900\n",
      "08/07 18:42:23 - mmengine - INFO - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.800\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.866\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.867\n",
      "08/07 18:42:23 - mmengine - INFO - segm_mAP_copypaste: 0.275 0.341 0.319 0.077 0.800 0.866\n",
      "08/07 18:42:23 - mmengine - INFO - Epoch(val) [18][8/8]    coco/bbox_mAP: 0.2790  coco/bbox_mAP_50: 0.3360  coco/bbox_mAP_75: 0.3170  coco/bbox_mAP_s: 0.0720  coco/bbox_mAP_m: 0.9000  coco/bbox_mAP_l: 0.9000  coco/segm_mAP: 0.2750  coco/segm_mAP_50: 0.3410  coco/segm_mAP_75: 0.3190  coco/segm_mAP_s: 0.0770  coco/segm_mAP_m: 0.8000  coco/segm_mAP_l: 0.8660  data_time: 0.3005  time: 0.7506\n",
      "08/07 18:42:23 - mmengine - INFO - The previous best checkpoint C:\\Users\\ja683\\Downloads\\saf\\tutorial_exps\\20-epochs-benchmark\\best_coco_bbox_mAP_epoch_15.pth is removed\n",
      "08/07 18:42:25 - mmengine - INFO - The best checkpoint with 0.2790 coco/bbox_mAP at 18 epoch is saved to best_coco_bbox_mAP_epoch_18.pth.\n",
      "08/07 18:42:25 - mmengine - INFO - The previous best checkpoint C:\\Users\\ja683\\Downloads\\saf\\tutorial_exps\\20-epochs-benchmark\\best_coco_segm_mAP_epoch_15.pth is removed\n",
      "08/07 18:42:27 - mmengine - INFO - The best checkpoint with 0.2750 coco/segm_mAP at 18 epoch is saved to best_coco_segm_mAP_epoch_18.pth.\n",
      "08/07 18:42:35 - mmengine - INFO - Epoch(train) [19][10/36]  lr: 2.5000e-04  eta: 0:00:30  time: 0.4315  data_time: 0.0487  memory: 5070  loss: 0.4199  loss_rpn_cls: 0.0005  loss_rpn_bbox: 0.0003  s0.loss_cls: 0.0236  s0.acc: 98.4375  s0.loss_bbox: 0.0029  s0.loss_mask: 0.1948  s1.loss_cls: 0.0155  s1.acc: 97.2656  s1.loss_bbox: 0.0095  s1.loss_mask: 0.0974  s2.loss_cls: 0.0131  s2.acc: 94.5312  s2.loss_bbox: 0.0143  s2.loss_mask: 0.0480\n",
      "08/07 18:42:39 - mmengine - INFO - Epoch(train) [19][20/36]  lr: 2.5000e-04  eta: 0:00:25  time: 0.4104  data_time: 0.0377  memory: 4424  loss: 0.4035  loss_rpn_cls: 0.0008  loss_rpn_bbox: 0.0005  s0.loss_cls: 0.0232  s0.acc: 98.6328  s0.loss_bbox: 0.0029  s0.loss_mask: 0.1854  s1.loss_cls: 0.0153  s1.acc: 97.8516  s1.loss_bbox: 0.0091  s1.loss_mask: 0.0928  s2.loss_cls: 0.0130  s2.acc: 97.0703  s2.loss_bbox: 0.0146  s2.loss_mask: 0.0458\n",
      "08/07 18:42:42 - mmengine - INFO - Epoch(train) [19][30/36]  lr: 2.5000e-04  eta: 0:00:20  time: 0.4074  data_time: 0.0380  memory: 5069  loss: 0.3998  loss_rpn_cls: 0.0011  loss_rpn_bbox: 0.0006  s0.loss_cls: 0.0224  s0.acc: 99.4141  s0.loss_bbox: 0.0027  s0.loss_mask: 0.1849  s1.loss_cls: 0.0145  s1.acc: 99.4141  s1.loss_bbox: 0.0086  s1.loss_mask: 0.0930  s2.loss_cls: 0.0122  s2.acc: 98.2422  s2.loss_bbox: 0.0139  s2.loss_mask: 0.0459\n",
      "08/07 18:42:45 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:42:45 - mmengine - INFO - Saving checkpoint at 19 epochs\n",
      "08/07 18:42:52 - mmengine - INFO - Epoch(train) [20][10/36]  lr: 2.5000e-05  eta: 0:00:12  time: 0.4162  data_time: 0.0456  memory: 5069  loss: 0.3980  loss_rpn_cls: 0.0008  loss_rpn_bbox: 0.0006  s0.loss_cls: 0.0228  s0.acc: 99.6094  s0.loss_bbox: 0.0028  s0.loss_mask: 0.1831  s1.loss_cls: 0.0152  s1.acc: 99.6094  s1.loss_bbox: 0.0088  s1.loss_mask: 0.0916  s2.loss_cls: 0.0128  s2.acc: 98.0469  s2.loss_bbox: 0.0142  s2.loss_mask: 0.0454\n",
      "08/07 18:42:56 - mmengine - INFO - Epoch(train) [20][20/36]  lr: 2.5000e-05  eta: 0:00:07  time: 0.3948  data_time: 0.0291  memory: 5062  loss: 0.4109  loss_rpn_cls: 0.0008  loss_rpn_bbox: 0.0006  s0.loss_cls: 0.0220  s0.acc: 99.0234  s0.loss_bbox: 0.0029  s0.loss_mask: 0.1899  s1.loss_cls: 0.0154  s1.acc: 98.0469  s1.loss_bbox: 0.0093  s1.loss_mask: 0.0949  s2.loss_cls: 0.0131  s2.acc: 96.4844  s2.loss_bbox: 0.0150  s2.loss_mask: 0.0470\n",
      "08/07 18:43:00 - mmengine - INFO - Epoch(train) [20][30/36]  lr: 2.5000e-05  eta: 0:00:02  time: 0.3921  data_time: 0.0294  memory: 4479  loss: 0.4039  loss_rpn_cls: 0.0004  loss_rpn_bbox: 0.0004  s0.loss_cls: 0.0211  s0.acc: 99.6094  s0.loss_bbox: 0.0027  s0.loss_mask: 0.1880  s1.loss_cls: 0.0152  s1.acc: 99.2188  s1.loss_bbox: 0.0088  s1.loss_mask: 0.0937  s2.loss_cls: 0.0129  s2.acc: 99.2188  s2.loss_bbox: 0.0143  s2.loss_mask: 0.0465\n",
      "08/07 18:43:02 - mmengine - INFO - Exp name: htc_x101-32x4d_fpn_16xb1-20e_coco_saf_20240807_183412\n",
      "08/07 18:43:02 - mmengine - INFO - Saving checkpoint at 20 epochs\n",
      "08/07 18:43:12 - mmengine - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.13s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.281\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.340\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.315\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.900\n",
      "08/07 18:43:12 - mmengine - INFO - bbox_mAP_copypaste: 0.281 0.340 0.315 0.075 0.900 0.900\n",
      "08/07 18:43:12 - mmengine - INFO - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.13s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.800\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.866\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.867\n",
      "08/07 18:43:12 - mmengine - INFO - segm_mAP_copypaste: 0.274 0.342 0.320 0.077 0.800 0.866\n",
      "08/07 18:43:12 - mmengine - INFO - Epoch(val) [20][8/8]    coco/bbox_mAP: 0.2810  coco/bbox_mAP_50: 0.3400  coco/bbox_mAP_75: 0.3150  coco/bbox_mAP_s: 0.0750  coco/bbox_mAP_m: 0.9000  coco/bbox_mAP_l: 0.9000  coco/segm_mAP: 0.2740  coco/segm_mAP_50: 0.3420  coco/segm_mAP_75: 0.3200  coco/segm_mAP_s: 0.0770  coco/segm_mAP_m: 0.8000  coco/segm_mAP_l: 0.8660  data_time: 0.2977  time: 0.7348\n",
      "08/07 18:43:12 - mmengine - INFO - The previous best checkpoint C:\\Users\\ja683\\Downloads\\saf\\tutorial_exps\\20-epochs-benchmark\\best_coco_bbox_mAP_epoch_18.pth is removed\n",
      "08/07 18:43:14 - mmengine - INFO - The best checkpoint with 0.2810 coco/bbox_mAP at 20 epoch is saved to best_coco_bbox_mAP_epoch_20.pth.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 5.5%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>coco/bbox_mAP</td><td></td></tr><tr><td>coco/bbox_mAP_50</td><td></td></tr><tr><td>coco/bbox_mAP_75</td><td></td></tr><tr><td>coco/bbox_mAP_l</td><td></td></tr><tr><td>coco/bbox_mAP_m</td><td></td></tr><tr><td>coco/bbox_mAP_s</td><td></td></tr><tr><td>coco/segm_mAP</td><td></td></tr><tr><td>coco/segm_mAP_50</td><td></td></tr><tr><td>coco/segm_mAP_75</td><td></td></tr><tr><td>coco/segm_mAP_l</td><td></td></tr><tr><td>coco/segm_mAP_m</td><td></td></tr><tr><td>coco/segm_mAP_s</td><td></td></tr><tr><td>data_time</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>iter</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>loss_rpn_bbox</td><td></td></tr><tr><td>loss_rpn_cls</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>memory</td><td></td></tr><tr><td>s0.acc</td><td></td></tr><tr><td>s0.loss_bbox</td><td></td></tr><tr><td>s0.loss_cls</td><td></td></tr><tr><td>s0.loss_mask</td><td></td></tr><tr><td>s1.acc</td><td></td></tr><tr><td>s1.loss_bbox</td><td></td></tr><tr><td>s1.loss_cls</td><td></td></tr><tr><td>s1.loss_mask</td><td></td></tr><tr><td>s2.acc</td><td></td></tr><tr><td>s2.loss_bbox</td><td></td></tr><tr><td>s2.loss_cls</td><td></td></tr><tr><td>s2.loss_mask</td><td></td></tr><tr><td>time</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>coco/bbox_mAP</td><td>0.281</td></tr><tr><td>coco/bbox_mAP_50</td><td>0.34</td></tr><tr><td>coco/bbox_mAP_75</td><td>0.315</td></tr><tr><td>coco/bbox_mAP_l</td><td>0.9</td></tr><tr><td>coco/bbox_mAP_m</td><td>0.9</td></tr><tr><td>coco/bbox_mAP_s</td><td>0.075</td></tr><tr><td>coco/segm_mAP</td><td>0.274</td></tr><tr><td>coco/segm_mAP_50</td><td>0.342</td></tr><tr><td>coco/segm_mAP_75</td><td>0.32</td></tr><tr><td>coco/segm_mAP_l</td><td>0.866</td></tr><tr><td>coco/segm_mAP_m</td><td>0.8</td></tr><tr><td>coco/segm_mAP_s</td><td>0.077</td></tr><tr><td>data_time</td><td>0.29766</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>iter</td><td>714</td></tr><tr><td>loss</td><td>0.40388</td></tr><tr><td>loss_rpn_bbox</td><td>0.00037</td></tr><tr><td>loss_rpn_cls</td><td>0.00039</td></tr><tr><td>lr</td><td>2e-05</td></tr><tr><td>memory</td><td>4479</td></tr><tr><td>s0.acc</td><td>99.60938</td></tr><tr><td>s0.loss_bbox</td><td>0.00272</td></tr><tr><td>s0.loss_cls</td><td>0.02106</td></tr><tr><td>s0.loss_mask</td><td>0.188</td></tr><tr><td>s1.acc</td><td>99.21875</td></tr><tr><td>s1.loss_bbox</td><td>0.0088</td></tr><tr><td>s1.loss_cls</td><td>0.01521</td></tr><tr><td>s1.loss_mask</td><td>0.09371</td></tr><tr><td>s2.acc</td><td>99.21875</td></tr><tr><td>s2.loss_bbox</td><td>0.01428</td></tr><tr><td>s2.loss_cls</td><td>0.01287</td></tr><tr><td>s2.loss_mask</td><td>0.04647</td></tr><tr><td>time</td><td>0.7348</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">avid-planet-51</strong> at: <a href='https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project/runs/ai7tlr1m' target=\"_blank\">https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project/runs/ai7tlr1m</a><br/> View project at: <a href='https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project' target=\"_blank\">https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project</a><br/>Synced 6 W&B file(s), 0 media file(s), 2190 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\tutorial_exps\\20-epochs-benchmark\\20240807_183412\\vis_data\\wandb\\run-20240807_183420-ai7tlr1m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the configuration\n",
    "cfg = Config.fromfile('mmdetection/configs/htc/htc_x101-32x4d_fpn_16xb1-20e_coco.py')\n",
    "\n",
    "# Initialize WandB\n",
    "# wandb.init(project='SAF_Project', entity='ahluwaliajyoti50-university-of-sussex', config={\n",
    "#     'learning_rate': cfg.optim_wrapper.optimizer.lr,\n",
    "#     'architecture': 'HTC_X101',\n",
    "#     'dataset': 'SAF22',\n",
    "#     'epochs': cfg.train_cfg.max_epochs,\n",
    "#     'batch_size': cfg.train_dataloader.batch_size,\n",
    "#     'optimizer': cfg.optim_wrapper.optimizer.type,\n",
    "#     'classes': cfg.metainfo['classes'],\n",
    "#     'work_dir': cfg.work_dir,\n",
    "#     'seed': 0,\n",
    "# })\n",
    "\n",
    "# Modify dataset classes and color\n",
    "cfg.metainfo = {\n",
    "    'classes': ('ClassicalEvaporation', 'TansitionalMixing', 'DiffusiveMixing', 'spray'),\n",
    "    'palette': [\n",
    "        (13,24,103), (167,13,13), (91,117,249), (203,173,55),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.data_root = 'mmdetection/data/saf22/'\n",
    "cfg.train_dataloader.dataset.ann_file = 'train/annotation_coco.json'\n",
    "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.train_dataloader.dataset.data_prefix = {'img': 'train/'}\n",
    "cfg.train_dataloader.dataset.metainfo = cfg.metainfo\n",
    "\n",
    "cfg.val_dataloader.dataset.ann_file = 'val/annotation_coco.json'\n",
    "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.val_dataloader.dataset.data_prefix = {'img': 'val/'}\n",
    "cfg.val_dataloader.dataset.metainfo = cfg.metainfo\n",
    "\n",
    "cfg.test_dataloader = cfg.val_dataloader\n",
    "\n",
    "# Modify metric config\n",
    "cfg.val_evaluator.ann_file = f'{cfg.data_root}val/annotation_coco.json'\n",
    "cfg.test_evaluator = cfg.val_evaluator\n",
    "\n",
    "# Modify num classes of the model in box head and mask head\n",
    "if isinstance(cfg.model.roi_head.bbox_head, list):\n",
    "    for head in cfg.model.roi_head.bbox_head:\n",
    "        head.num_classes = 4\n",
    "else:\n",
    "    cfg.model.roi_head.bbox_head.num_classes = 4\n",
    "\n",
    "if isinstance(cfg.model.roi_head.mask_head, list):\n",
    "    for head in cfg.model.roi_head.mask_head:\n",
    "        head.num_classes = 4\n",
    "else:\n",
    "    cfg.model.roi_head.mask_head.num_classes = 4\n",
    "\n",
    "# Configure checkpoint saving\n",
    "cfg.default_hooks.checkpoint = dict(\n",
    "    type='CheckpointHook',\n",
    "    interval=1,\n",
    "    save_optimizer=True,\n",
    "    save_best = ['coco/bbox_mAP','coco/segm_mAP'],\n",
    "    save_last=True,\n",
    "    rule='greater',\n",
    "    max_keep_ckpts=1\n",
    ")\n",
    "\n",
    "cfg.test_evaluator.update(dict(classwise=True))\n",
    "\n",
    "# Use the pre-trained HTC model\n",
    "cfg.load_from = 'mmdetection/configs/htc/htc_x101_32x4d_fpn_16x1_20e_coco_20200318-de97ae01.pth'\n",
    "\n",
    "# Set up working dir to save files and logs\n",
    "cfg.work_dir = './tutorial_exps/20-epochs-benchmark'\n",
    "\n",
    "# Set the number of epochs\n",
    "cfg.train_cfg.max_epochs = 20\n",
    "\n",
    "# Set the evaluation interval\n",
    "cfg.train_cfg.val_interval = 3\n",
    "\n",
    "# Adjust learning rate for single GPU\n",
    "cfg.optim_wrapper.optimizer.lr = 0.02 / 8\n",
    "\n",
    "# Set logging interval\n",
    "cfg.default_hooks.logger.interval = 10\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_random_seed(0, deterministic=False)\n",
    "\n",
    "# Use Tensorboard to log the training process\n",
    "cfg.visualizer.vis_backends.append({\"type\": 'TensorboardVisBackend'})\n",
    "\n",
    "# Configure WandB logger\n",
    "cfg.visualizer.vis_backends.append(dict(type='WandbVisBackend', init_kwargs=dict(\n",
    "    project='SAF_Project',\n",
    "    entity='ahluwaliajyoti50-university-of-sussex',\n",
    "    config={\n",
    "        'learning_rate': cfg.optim_wrapper.optimizer.lr,\n",
    "        'architecture': 'HTC_X101',\n",
    "        'dataset': 'SAF22',\n",
    "        'epochs': cfg.train_cfg.max_epochs,\n",
    "        'batch_size': cfg.train_dataloader.batch_size,\n",
    "        'optimizer': cfg.optim_wrapper.optimizer.type,\n",
    "        'classes': cfg.metainfo['classes'],\n",
    "        'seed': 0,\n",
    "    }\n",
    ")))\n",
    "\n",
    "# Save the modified config\n",
    "config = 'mmdetection/configs/htc/htc_x101-32x4d_fpn_16xb1-20e_coco_saf.py'\n",
    "with open(config, 'w') as f:\n",
    "    f.write(cfg.pretty_text)\n",
    "\n",
    "# Train using train.py\n",
    "%run mmdetection/tools/train.py {config}\n",
    "\n",
    "# [Optional] Finish the wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f6aefd-79a0-4d79-89dc-d9e5f44d6558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6078122-b475-44a7-98e2-74e5d303c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = 'mmdetection/configs/htc/htc_x101-32x4d_fpn_16xb1-20e_coco_saf.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58927021-d583-4e22-b016-b3c18272cf0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bc097ad-5868-4ef0-8945-61b977f4aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "ckpt = 'tutorial_exps/20-epochs-benchmark/best_coco_segm_mAP_epoch_18.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57124db2-167e-43f7-bb85-85f518384a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tutorial_exps/20-epochs-benchmark/best_coco_bbox_mAP_epoch_20.pth'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_b  = 'tutorial_exps/20-epochs-benchmark/best_coco_bbox_mAP_epoch_20.pth'\n",
    "ckpt_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c10a0d-ed46-47bf-b752-50d4558a8608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63b4e8b6-5250-4c86-ac22-45422e91da42",
   "metadata": {},
   "source": [
    "## Test HTC on best checkpointfile and save the painted images for future visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f225e66a-867a-4c7a-b1e6-d422efedfcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcd1f7e7-b463-4fcb-a939-5b13dd63b35d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/07 18:45:39 - mmengine - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: ahluwaliajyoti50 (ahluwaliajyoti50-university-of-sussex). Use `wandb login --relogin` to force relogin"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb: Tracking run with wandb version 0.17.5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb: Run data is saved locally in C:\\Users\\ja683\\Downloads\\saf\\tutorial_exps\\20-epochs-benchmark\\20240807_184531\\vis_data\\wandb\\run-20240807_184543-n0hw57vf"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Run `wandb offline` to turn off syncing."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System environment:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb: Syncing run cool-firebrand-52"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb:  View project at https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sys.platform: win32"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:  View run at https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project/runs/n0hw57vf"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\users\\ja683\\downloads\\saf\\mmdetection\\mmdet\\models\\roi_heads\\mask_heads\\fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor)."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CUDA available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  mask_preds = bboxes.new_tensor(mask_preds)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MUSA available: False"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    numpy_random_seed: 469880171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ja683\\AppData\\Roaming\\Python\\Python310\\site-packages\\mmengine\\visualization\\visualizer.py:760: UserWarning: Warning: The bbox is out of bounds, the drawn bbox may not be in the image"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    GPU 0: NVIDIA RTX A4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  warnings.warn("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.66"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ja683\\AppData\\Roaming\\Python\\Python310\\site-packages\\mmengine\\visualization\\visualizer.py:831: UserWarning: Warning: The polygon is out of bounds, the drawn polygon may not be in the image"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MSVC: Microsoft (R) C/C++ Optimizing Compiler Version 19.35.32216.1 for x64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  warnings.warn("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    GCC: n/a"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: - 9.740 MB of 9.740 MB uploaded (0.547 MB deduped)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PyTorch: 2.3.1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: \\ 9.740 MB of 9.740 MB uploaded (0.547 MB deduped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: | 9.740 MB of 9.740 MB uploaded (0.547 MB deduped)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PyTorch compiling details: PyTorch built with:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - C++ Version: 201703"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: / 9.822 MB of 9.856 MB uploaded (0.550 MB deduped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - MSVC 192930154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: - 9.829 MB of 9.856 MB uploaded (0.550 MB deduped)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb: \\ 9.829 MB of 9.856 MB uploaded (0.550 MB deduped)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: | 9.856 MB of 9.856 MB uploaded (0.550 MB deduped)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb:                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - OpenMP 2019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - LAPACK is enabled (usually provided by MKL)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: W&B sync reduced upload amount by 5.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - CPU capability usage: AVX2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:  View run cool-firebrand-52 at: https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project/runs/n0hw57vf"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - CUDA Runtime 12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:  View project at: https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Synced 6 W&B file(s), 0 media file(s), 2184 artifact file(s) and 0 other file(s)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - CuDNN 8.9.7  (built against CUDA 12.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Find logs at: .\\tutorial_exps\\20-epochs-benchmark\\20240807_184531\\vis_data\\wandb\\run-20240807_184543-n0hw57vf\\logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Magma 2.5.4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.7, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    TorchVision: 0.18.1\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 469880171\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/07 18:45:40 - mmengine - INFO - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'mmdetection/data/saf22/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=1,\n",
      "        max_keep_ckpts=1,\n",
      "        rule='greater',\n",
      "        save_best=[\n",
      "            'coco/bbox_mAP',\n",
      "            'coco/segm_mAP',\n",
      "        ],\n",
      "        save_last=True,\n",
      "        save_optimizer=True,\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(\n",
      "        draw=True, test_out_dir='output/segm', type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "launcher = 'none'\n",
      "load_from = 'tutorial_exps/20-epochs-benchmark/best_coco_segm_mAP_epoch_18.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 20\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'ClassicalEvaporation',\n",
      "        'TansitionalMixing',\n",
      "        'DiffusiveMixing',\n",
      "        'spray',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            13,\n",
      "            24,\n",
      "            103,\n",
      "        ),\n",
      "        (\n",
      "            167,\n",
      "            13,\n",
      "            13,\n",
      "        ),\n",
      "        (\n",
      "            91,\n",
      "            117,\n",
      "            249,\n",
      "        ),\n",
      "        (\n",
      "            203,\n",
      "            173,\n",
      "            55,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_seg=True,\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                        0.2,\n",
      "                        0.2,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=4,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.05,\n",
      "                        0.05,\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=4,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.033,\n",
      "                        0.033,\n",
      "                        0.067,\n",
      "                        0.067,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=4,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "        ],\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        interleaved=True,\n",
      "        mask_head=[\n",
      "            dict(\n",
      "                conv_out_channels=256,\n",
      "                in_channels=256,\n",
      "                loss_mask=dict(\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "                num_classes=4,\n",
      "                num_convs=4,\n",
      "                type='HTCMaskHead',\n",
      "                with_conv_res=False),\n",
      "            dict(\n",
      "                conv_out_channels=256,\n",
      "                in_channels=256,\n",
      "                loss_mask=dict(\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "                num_classes=4,\n",
      "                num_convs=4,\n",
      "                type='HTCMaskHead'),\n",
      "            dict(\n",
      "                conv_out_channels=256,\n",
      "                in_channels=256,\n",
      "                loss_mask=dict(\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "                num_classes=4,\n",
      "                num_convs=4,\n",
      "                type='HTCMaskHead'),\n",
      "        ],\n",
      "        mask_info_flow=True,\n",
      "        mask_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        num_stages=3,\n",
      "        semantic_head=None,\n",
      "        semantic_roi_extractor=None,\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            0.5,\n",
      "            0.25,\n",
      "        ],\n",
      "        type='HybridTaskCascadeRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(\n",
      "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            mask_thr_binary=0.5,\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.001),\n",
      "        rpn=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=1000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    pos_iou_thr=0.5,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    pos_iou_thr=0.6,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    pos_iou_thr=0.7,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "        ],\n",
      "        rpn=dict(\n",
      "            allowed_border=0,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    type='HybridTaskCascade')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.0025, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=20,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            16,\n",
      "            19,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='val/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val/'),\n",
      "        data_root='mmdetection/data/saf22/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'ClassicalEvaporation',\n",
      "                'TansitionalMixing',\n",
      "                'DiffusiveMixing',\n",
      "                'spray',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    13,\n",
      "                    24,\n",
      "                    103,\n",
      "                ),\n",
      "                (\n",
      "                    167,\n",
      "                    13,\n",
      "                    13,\n",
      "                ),\n",
      "                (\n",
      "                    91,\n",
      "                    117,\n",
      "                    249,\n",
      "                ),\n",
      "                (\n",
      "                    203,\n",
      "                    173,\n",
      "                    55,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='mmdetection/data/saf22/val/annotation_coco.json',\n",
      "    backend_args=None,\n",
      "    classwise=True,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=20, type='EpochBasedTrainLoop', val_interval=3)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='train/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='train/'),\n",
      "        data_root='mmdetection/data/saf22/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'ClassicalEvaporation',\n",
      "                'TansitionalMixing',\n",
      "                'DiffusiveMixing',\n",
      "                'spray',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    13,\n",
      "                    24,\n",
      "                    103,\n",
      "                ),\n",
      "                (\n",
      "                    167,\n",
      "                    13,\n",
      "                    13,\n",
      "                ),\n",
      "                (\n",
      "                    91,\n",
      "                    117,\n",
      "                    249,\n",
      "                ),\n",
      "                (\n",
      "                    203,\n",
      "                    173,\n",
      "                    55,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='LoadAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_mask=True,\n",
      "                with_seg=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='val/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val/'),\n",
      "        data_root='mmdetection/data/saf22/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'ClassicalEvaporation',\n",
      "                'TansitionalMixing',\n",
      "                'DiffusiveMixing',\n",
      "                'spray',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    13,\n",
      "                    24,\n",
      "                    103,\n",
      "                ),\n",
      "                (\n",
      "                    167,\n",
      "                    13,\n",
      "                    13,\n",
      "                ),\n",
      "                (\n",
      "                    91,\n",
      "                    117,\n",
      "                    249,\n",
      "                ),\n",
      "                (\n",
      "                    203,\n",
      "                    173,\n",
      "                    55,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='mmdetection/data/saf22/val/annotation_coco.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(type='TensorboardVisBackend'),\n",
      "        dict(\n",
      "            init_kwargs=dict(\n",
      "                config=dict(\n",
      "                    architecture='HTC_X101',\n",
      "                    batch_size=1,\n",
      "                    classes=(\n",
      "                        'ClassicalEvaporation',\n",
      "                        'TansitionalMixing',\n",
      "                        'DiffusiveMixing',\n",
      "                        'spray',\n",
      "                    ),\n",
      "                    dataset='SAF22',\n",
      "                    epochs=20,\n",
      "                    learning_rate=0.0025,\n",
      "                    optimizer='SGD',\n",
      "                    seed=0),\n",
      "                entity='ahluwaliajyoti50-university-of-sussex',\n",
      "                project='SAF_Project'),\n",
      "            type='WandbVisBackend'),\n",
      "    ])\n",
      "work_dir = './tutorial_exps/20-epochs-benchmark'\n",
      "\n",
      "08/07 18:46:06 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/07 18:46:06 - mmengine - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Loads checkpoint by local backend from path: tutorial_exps/20-epochs-benchmark/best_coco_segm_mAP_epoch_18.pth\n",
      "08/07 18:46:11 - mmengine - INFO - Load checkpoint from tutorial_exps/20-epochs-benchmark/best_coco_segm_mAP_epoch_18.pth\n",
      "08/07 18:47:36 - mmengine - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.11s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.336\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.317\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.900\n",
      "08/07 18:47:36 - mmengine - INFO - \n",
      "+----------------------+-------+--------+--------+-------+-------+-------+\n",
      "| category             | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\n",
      "+----------------------+-------+--------+--------+-------+-------+-------+\n",
      "| ClassicalEvaporation | 0.076 | 0.105  | 0.102  | 0.063 | 0.9   | nan   |\n",
      "| TansitionalMixing    | 0.119 | 0.198  | 0.143  | 0.132 | nan   | nan   |\n",
      "| DiffusiveMixing      | 0.022 | 0.04   | 0.023  | 0.022 | nan   | nan   |\n",
      "| spray                | 0.9   | 1.0    | 1.0    | nan   | nan   | 0.9   |\n",
      "+----------------------+-------+--------+--------+-------+-------+-------+\n",
      "08/07 18:47:36 - mmengine - INFO - bbox_mAP_copypaste: 0.279 0.336 0.317 0.072 0.900 0.900\n",
      "08/07 18:47:36 - mmengine - INFO - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.800\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.866\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.867\n",
      "08/07 18:47:36 - mmengine - INFO - \n",
      "+----------------------+-------+--------+--------+-------+-------+-------+\n",
      "| category             | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\n",
      "+----------------------+-------+--------+--------+-------+-------+-------+\n",
      "| ClassicalEvaporation | 0.087 | 0.112  | 0.108  | 0.072 | 0.8   | nan   |\n",
      "| TansitionalMixing    | 0.124 | 0.205  | 0.148  | 0.136 | nan   | nan   |\n",
      "| DiffusiveMixing      | 0.021 | 0.049  | 0.021  | 0.021 | nan   | nan   |\n",
      "| spray                | 0.866 | 1.0    | 1.0    | nan   | nan   | 0.866 |\n",
      "+----------------------+-------+--------+--------+-------+-------+-------+\n",
      "08/07 18:47:36 - mmengine - INFO - segm_mAP_copypaste: 0.275 0.341 0.319 0.077 0.800 0.866\n",
      "08/07 18:47:36 - mmengine - INFO - Epoch(test) [8/8]    coco/ClassicalEvaporation_precision: 0.0870  coco/TansitionalMixing_precision: 0.1240  coco/DiffusiveMixing_precision: 0.0210  coco/spray_precision: 0.8660  coco/bbox_mAP: 0.2790  coco/bbox_mAP_50: 0.3360  coco/bbox_mAP_75: 0.3170  coco/bbox_mAP_s: 0.0720  coco/bbox_mAP_m: 0.9000  coco/bbox_mAP_l: 0.9000  coco/segm_mAP: 0.2750  coco/segm_mAP_50: 0.3410  coco/segm_mAP_75: 0.3190  coco/segm_mAP_s: 0.0770  coco/segm_mAP_m: 0.8000  coco/segm_mAP_l: 0.8660  data_time: 8.3568  time: 10.4802\n"
     ]
    }
   ],
   "source": [
    "!python mmdetection/tools/test.py {config} {ckpt} --show-dir output/segm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d441e-1cc7-46b2-9649-63f6f7c101d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aca06d96-82d6-465c-b86a-5e1259807b87",
   "metadata": {},
   "source": [
    "## Inference on trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "727613d2-de8a-43a3-8097-0b19df8475f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: tutorial_exps/20-epochs-benchmark/best_coco_segm_mAP_epoch_18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ja683\\AppData\\Roaming\\Python\\Python310\\site-packages\\mmengine\\utils\\manager.py:113: UserWarning: <class 'mmdet.visualization.local_visualizer.DetLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "import mmcv\n",
    "import cv2\n",
    "from mmdet.registry import VISUALIZERS\n",
    "\n",
    "model = init_detector(config, ckpt, device='cuda:0')\n",
    "\n",
    "image_folder = 'mmdetection/data/saf22/test/'\n",
    "output_folder = 'tutorial_exps/20-epochs-benchmark/inference-results/segm'\n",
    "image_paths = [os.path.join(image_folder, img_name) for img_name in os.listdir(image_folder) if img_name.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'tiff'))]\n",
    "\n",
    "visualizer = VISUALIZERS.build(model.cfg.visualizer)\n",
    "visualizer.dataset_meta = model.dataset_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "067cad08-f054-44cb-bb04-9d50d0273ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in image_paths:\n",
    "    img = mmcv.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Failed to read image at {img_path}\")\n",
    "        continue\n",
    "    \n",
    "    new_result_segm = inference_detector(model, img)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_file = os.path.join(output_folder, os.path.basename(img_path))\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    visualizer.add_datasample(\n",
    "        'new_result_segm',\n",
    "        img_rgb,\n",
    "        data_sample=new_result_segm,        draw_gt=None,\n",
    "        wait_time=0,\n",
    "        out_file=output_file\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d11fab-8246-40b8-93b0-27d5498115b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8df4e632-6211-43f6-924f-55b46a46bfa8",
   "metadata": {},
   "source": [
    "### save results.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5b85f64-3fd1-471d-95a8-343156d686d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/07 18:50:24 - mmengine - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: ahluwaliajyoti50 (ahluwaliajyoti50-university-of-sussex). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Tracking run with wandb version 0.17.5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Run data is saved locally in C:\\Users\\ja683\\Downloads\\saf\\tutorial_exps\\20-epochs-benchmark\\20240807_185018\\vis_data\\wandb\\run-20240807_185027-h17po8h8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System environment:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb: Run `wandb offline` to turn off syncing."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sys.platform: win32"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Syncing run chocolate-glade-53"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb:  View project at https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CUDA available: True"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:  View run at https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project/runs/h17po8h8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MUSA available: False"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ja683\\downloads\\saf\\mmdetection\\mmdet\\models\\roi_heads\\mask_heads\\fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  mask_preds = bboxes.new_tensor(mask_preds)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb: - 9.759 MB of 9.759 MB uploaded (9.739 MB deduped)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    numpy_random_seed: 1082448075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: \\ 9.759 MB of 9.759 MB uploaded (9.739 MB deduped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    GPU 0: NVIDIA RTX A4000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: | 9.759 MB of 9.759 MB uploaded (9.739 MB deduped)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: / 9.759 MB of 9.759 MB uploaded (9.739 MB deduped)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.66"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb: - 9.840 MB of 9.873 MB uploaded (9.742 MB deduped)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    MSVC: Microsoft (R) C/C++ Optimizing Compiler Version 19.35.32216.1 for x64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    GCC: n/a\n",
      "    PyTorch: 2.3.1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: \\ 9.847 MB of 9.873 MB uploaded (9.742 MB deduped)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    PyTorch compiling details: PyTorch built with:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb: | 9.847 MB of 9.873 MB uploaded (9.742 MB deduped)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - C++ Version: 201703"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - MSVC 192930154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: / 9.873 MB of 9.873 MB uploaded (9.742 MB deduped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb: W&B sync reduced upload amount by 98.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:  View run chocolate-glade-53 at: https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project/runs/h17po8h8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - OpenMP 2019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:  View project at: https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Synced 6 W&B file(s), 0 media file(s), 2185 artifact file(s) and 0 other file(s)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - LAPACK is enabled (usually provided by MKL)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb: Find logs at: .\\tutorial_exps\\20-epochs-benchmark\\20240807_185018\\vis_data\\wandb\\run-20240807_185027-h17po8h8\\logs"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - CPU capability usage: AVX2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.7  (built against CUDA 12.2)\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.7, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.18.1\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1082448075\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/07 18:50:24 - mmengine - INFO - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'mmdetection/data/saf22/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=1,\n",
      "        max_keep_ckpts=1,\n",
      "        rule='greater',\n",
      "        save_best=[\n",
      "            'coco/bbox_mAP',\n",
      "            'coco/segm_mAP',\n",
      "        ],\n",
      "        save_last=True,\n",
      "        save_optimizer=True,\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "launcher = 'none'\n",
      "load_from = 'tutorial_exps/20-epochs-benchmark/best_coco_segm_mAP_epoch_18.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 20\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'ClassicalEvaporation',\n",
      "        'TansitionalMixing',\n",
      "        'DiffusiveMixing',\n",
      "        'spray',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            13,\n",
      "            24,\n",
      "            103,\n",
      "        ),\n",
      "        (\n",
      "            167,\n",
      "            13,\n",
      "            13,\n",
      "        ),\n",
      "        (\n",
      "            91,\n",
      "            117,\n",
      "            249,\n",
      "        ),\n",
      "        (\n",
      "            203,\n",
      "            173,\n",
      "            55,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_seg=True,\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                        0.2,\n",
      "                        0.2,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=4,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.05,\n",
      "                        0.05,\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=4,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.033,\n",
      "                        0.033,\n",
      "                        0.067,\n",
      "                        0.067,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=4,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "        ],\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        interleaved=True,\n",
      "        mask_head=[\n",
      "            dict(\n",
      "                conv_out_channels=256,\n",
      "                in_channels=256,\n",
      "                loss_mask=dict(\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "                num_classes=4,\n",
      "                num_convs=4,\n",
      "                type='HTCMaskHead',\n",
      "                with_conv_res=False),\n",
      "            dict(\n",
      "                conv_out_channels=256,\n",
      "                in_channels=256,\n",
      "                loss_mask=dict(\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "                num_classes=4,\n",
      "                num_convs=4,\n",
      "                type='HTCMaskHead'),\n",
      "            dict(\n",
      "                conv_out_channels=256,\n",
      "                in_channels=256,\n",
      "                loss_mask=dict(\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "                num_classes=4,\n",
      "                num_convs=4,\n",
      "                type='HTCMaskHead'),\n",
      "        ],\n",
      "        mask_info_flow=True,\n",
      "        mask_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        num_stages=3,\n",
      "        semantic_head=None,\n",
      "        semantic_roi_extractor=None,\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            0.5,\n",
      "            0.25,\n",
      "        ],\n",
      "        type='HybridTaskCascadeRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(\n",
      "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            mask_thr_binary=0.5,\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.001),\n",
      "        rpn=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=1000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    pos_iou_thr=0.5,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    pos_iou_thr=0.6,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    pos_iou_thr=0.7,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "        ],\n",
      "        rpn=dict(\n",
      "            allowed_border=0,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    type='HybridTaskCascade')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.0025, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=20,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            16,\n",
      "            19,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='val/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val/'),\n",
      "        data_root='mmdetection/data/saf22/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'ClassicalEvaporation',\n",
      "                'TansitionalMixing',\n",
      "                'DiffusiveMixing',\n",
      "                'spray',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    13,\n",
      "                    24,\n",
      "                    103,\n",
      "                ),\n",
      "                (\n",
      "                    167,\n",
      "                    13,\n",
      "                    13,\n",
      "                ),\n",
      "                (\n",
      "                    91,\n",
      "                    117,\n",
      "                    249,\n",
      "                ),\n",
      "                (\n",
      "                    203,\n",
      "                    173,\n",
      "                    55,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='mmdetection/data/saf22/val/annotation_coco.json',\n",
      "    backend_args=None,\n",
      "    classwise=True,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=20, type='EpochBasedTrainLoop', val_interval=3)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='train/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='train/'),\n",
      "        data_root='mmdetection/data/saf22/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'ClassicalEvaporation',\n",
      "                'TansitionalMixing',\n",
      "                'DiffusiveMixing',\n",
      "                'spray',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    13,\n",
      "                    24,\n",
      "                    103,\n",
      "                ),\n",
      "                (\n",
      "                    167,\n",
      "                    13,\n",
      "                    13,\n",
      "                ),\n",
      "                (\n",
      "                    91,\n",
      "                    117,\n",
      "                    249,\n",
      "                ),\n",
      "                (\n",
      "                    203,\n",
      "                    173,\n",
      "                    55,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='LoadAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_mask=True,\n",
      "                with_seg=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='val/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val/'),\n",
      "        data_root='mmdetection/data/saf22/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'ClassicalEvaporation',\n",
      "                'TansitionalMixing',\n",
      "                'DiffusiveMixing',\n",
      "                'spray',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    13,\n",
      "                    24,\n",
      "                    103,\n",
      "                ),\n",
      "                (\n",
      "                    167,\n",
      "                    13,\n",
      "                    13,\n",
      "                ),\n",
      "                (\n",
      "                    91,\n",
      "                    117,\n",
      "                    249,\n",
      "                ),\n",
      "                (\n",
      "                    203,\n",
      "                    173,\n",
      "                    55,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='mmdetection/data/saf22/val/annotation_coco.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(type='TensorboardVisBackend'),\n",
      "        dict(\n",
      "            init_kwargs=dict(\n",
      "                config=dict(\n",
      "                    architecture='HTC_X101',\n",
      "                    batch_size=1,\n",
      "                    classes=(\n",
      "                        'ClassicalEvaporation',\n",
      "                        'TansitionalMixing',\n",
      "                        'DiffusiveMixing',\n",
      "                        'spray',\n",
      "                    ),\n",
      "                    dataset='SAF22',\n",
      "                    epochs=20,\n",
      "                    learning_rate=0.0025,\n",
      "                    optimizer='SGD',\n",
      "                    seed=0),\n",
      "                entity='ahluwaliajyoti50-university-of-sussex',\n",
      "                project='SAF_Project'),\n",
      "            type='WandbVisBackend'),\n",
      "    ])\n",
      "work_dir = './tutorial_exps/20-epochs-benchmark'\n",
      "\n",
      "08/07 18:50:44 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/07 18:50:44 - mmengine - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "08/07 18:50:44 - mmengine - WARNING - The prefix is not set in metric class DumpDetResults.\n",
      "Loads checkpoint by local backend from path: tutorial_exps/20-epochs-benchmark/best_coco_segm_mAP_epoch_18.pth\n",
      "08/07 18:50:45 - mmengine - INFO - Load checkpoint from tutorial_exps/20-epochs-benchmark/best_coco_segm_mAP_epoch_18.pth\n",
      "08/07 18:51:04 - mmengine - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.11s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.336\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.317\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.900\n",
      "08/07 18:51:04 - mmengine - INFO - \n",
      "+----------------------+-------+--------+--------+-------+-------+-------+\n",
      "| category             | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\n",
      "+----------------------+-------+--------+--------+-------+-------+-------+\n",
      "| ClassicalEvaporation | 0.076 | 0.105  | 0.102  | 0.063 | 0.9   | nan   |\n",
      "| TansitionalMixing    | 0.119 | 0.198  | 0.143  | 0.132 | nan   | nan   |\n",
      "| DiffusiveMixing      | 0.022 | 0.04   | 0.023  | 0.022 | nan   | nan   |\n",
      "| spray                | 0.9   | 1.0    | 1.0    | nan   | nan   | 0.9   |\n",
      "+----------------------+-------+--------+--------+-------+-------+-------+\n",
      "08/07 18:51:04 - mmengine - INFO - bbox_mAP_copypaste: 0.279 0.336 0.317 0.072 0.900 0.900\n",
      "08/07 18:51:04 - mmengine - INFO - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.11s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.800\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.866\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.867\n",
      "08/07 18:51:04 - mmengine - INFO - \n",
      "+----------------------+-------+--------+--------+-------+-------+-------+\n",
      "| category             | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\n",
      "+----------------------+-------+--------+--------+-------+-------+-------+\n",
      "| ClassicalEvaporation | 0.087 | 0.112  | 0.108  | 0.072 | 0.8   | nan   |\n",
      "| TansitionalMixing    | 0.124 | 0.205  | 0.148  | 0.136 | nan   | nan   |\n",
      "| DiffusiveMixing      | 0.021 | 0.049  | 0.021  | 0.021 | nan   | nan   |\n",
      "| spray                | 0.866 | 1.0    | 1.0    | nan   | nan   | 0.866 |\n",
      "+----------------------+-------+--------+--------+-------+-------+-------+\n",
      "08/07 18:51:04 - mmengine - INFO - segm_mAP_copypaste: 0.275 0.341 0.319 0.077 0.800 0.866\n",
      "08/07 18:51:04 - mmengine - INFO - Results has been saved to ./results/20-epochs-benchmark/results.pkl.\n",
      "08/07 18:51:04 - mmengine - INFO - Epoch(test) [8/8]    coco/ClassicalEvaporation_precision: 0.0870  coco/TansitionalMixing_precision: 0.1240  coco/DiffusiveMixing_precision: 0.0210  coco/spray_precision: 0.8660  coco/bbox_mAP: 0.2790  coco/bbox_mAP_50: 0.3360  coco/bbox_mAP_75: 0.3170  coco/bbox_mAP_s: 0.0720  coco/bbox_mAP_m: 0.9000  coco/bbox_mAP_l: 0.9000  coco/segm_mAP: 0.2750  coco/segm_mAP_50: 0.3410  coco/segm_mAP_75: 0.3190  coco/segm_mAP_s: 0.0770  coco/segm_mAP_m: 0.8000  coco/segm_mAP_l: 0.8660  data_time: 1.1996  time: 2.3418\n"
     ]
    }
   ],
   "source": [
    "!python mmdetection/tools/test.py {config} {ckpt}  --out ./results/20-epochs-benchmark/results.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e83432-0149-42d7-8415-6af96388cf19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d963d4d-09cc-4757-9c4b-be1d9b84ecb6",
   "metadata": {},
   "source": [
    "## Log Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c95e1ccb-8bd6-49b8-ba74-96bc551afc31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: matplotlib\n",
      "Version: 3.9.1\n",
      "Summary: Python plotting package\n",
      "Home-page: \n",
      "Author: John D. Hunter, Michael Droettboom\n",
      "Author-email: Unknown <matplotlib-users@python.org>\n",
      "License: License agreement for matplotlib versions 1.3.0 and later\n",
      "        =========================================================\n",
      "        \n",
      "        1. This LICENSE AGREEMENT is between the Matplotlib Development Team\n",
      "        (\"MDT\"), and the Individual or Organization (\"Licensee\") accessing and\n",
      "        otherwise using matplotlib software in source or binary form and its\n",
      "        associated documentation.\n",
      "        \n",
      "        2. Subject to the terms and conditions of this License Agreement, MDT\n",
      "        hereby grants Licensee a nonexclusive, royalty-free, world-wide license\n",
      "        to reproduce, analyze, test, perform and/or display publicly, prepare\n",
      "        derivative works, distribute, and otherwise use matplotlib\n",
      "        alone or in any derivative version, provided, however, that MDT's\n",
      "        License Agreement and MDT's notice of copyright, i.e., \"Copyright (c)\n",
      "        2012- Matplotlib Development Team; All Rights Reserved\" are retained in\n",
      "        matplotlib  alone or in any derivative version prepared by\n",
      "        Licensee.\n",
      "        \n",
      "        3. In the event Licensee prepares a derivative work that is based on or\n",
      "        incorporates matplotlib or any part thereof, and wants to\n",
      "        make the derivative work available to others as provided herein, then\n",
      "        Licensee hereby agrees to include in any such work a brief summary of\n",
      "        the changes made to matplotlib .\n",
      "        \n",
      "        4. MDT is making matplotlib available to Licensee on an \"AS\n",
      "        IS\" basis.  MDT MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\n",
      "        IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, MDT MAKES NO AND\n",
      "        DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\n",
      "        FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF MATPLOTLIB\n",
      "        WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.\n",
      "        \n",
      "        5. MDT SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF MATPLOTLIB\n",
      "         FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR\n",
      "        LOSS AS A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING\n",
      "        MATPLOTLIB , OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF\n",
      "        THE POSSIBILITY THEREOF.\n",
      "        \n",
      "        6. This License Agreement will automatically terminate upon a material\n",
      "        breach of its terms and conditions.\n",
      "        \n",
      "        7. Nothing in this License Agreement shall be deemed to create any\n",
      "        relationship of agency, partnership, or joint venture between MDT and\n",
      "        Licensee.  This License Agreement does not grant permission to use MDT\n",
      "        trademarks or trade name in a trademark sense to endorse or promote\n",
      "        products or services of Licensee, or any third party.\n",
      "        \n",
      "        8. By copying, installing or otherwise using matplotlib ,\n",
      "        Licensee agrees to be bound by the terms and conditions of this License\n",
      "        Agreement.\n",
      "        \n",
      "        License agreement for matplotlib versions prior to 1.3.0\n",
      "        ========================================================\n",
      "        \n",
      "        1. This LICENSE AGREEMENT is between John D. Hunter (\"JDH\"), and the\n",
      "        Individual or Organization (\"Licensee\") accessing and otherwise using\n",
      "        matplotlib software in source or binary form and its associated\n",
      "        documentation.\n",
      "        \n",
      "        2. Subject to the terms and conditions of this License Agreement, JDH\n",
      "        hereby grants Licensee a nonexclusive, royalty-free, world-wide license\n",
      "        to reproduce, analyze, test, perform and/or display publicly, prepare\n",
      "        derivative works, distribute, and otherwise use matplotlib\n",
      "        alone or in any derivative version, provided, however, that JDH's\n",
      "        License Agreement and JDH's notice of copyright, i.e., \"Copyright (c)\n",
      "        2002-2011 John D. Hunter; All Rights Reserved\" are retained in\n",
      "        matplotlib  alone or in any derivative version prepared by\n",
      "        Licensee.\n",
      "        \n",
      "        3. In the event Licensee prepares a derivative work that is based on or\n",
      "        incorporates matplotlib  or any part thereof, and wants to\n",
      "        make the derivative work available to others as provided herein, then\n",
      "        Licensee hereby agrees to include in any such work a brief summary of\n",
      "        the changes made to matplotlib.\n",
      "        \n",
      "        4. JDH is making matplotlib  available to Licensee on an \"AS\n",
      "        IS\" basis.  JDH MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\n",
      "        IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, JDH MAKES NO AND\n",
      "        DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\n",
      "        FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF MATPLOTLIB\n",
      "        WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.\n",
      "        \n",
      "        5. JDH SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF MATPLOTLIB\n",
      "         FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR\n",
      "        LOSS AS A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING\n",
      "        MATPLOTLIB , OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF\n",
      "        THE POSSIBILITY THEREOF.\n",
      "        \n",
      "        6. This License Agreement will automatically terminate upon a material\n",
      "        breach of its terms and conditions.\n",
      "        \n",
      "        7. Nothing in this License Agreement shall be deemed to create any\n",
      "        relationship of agency, partnership, or joint venture between JDH and\n",
      "        Licensee.  This License Agreement does not grant permission to use JDH\n",
      "        trademarks or trade name in a trademark sense to endorse or promote\n",
      "        products or services of Licensee, or any third party.\n",
      "        \n",
      "        8. By copying, installing or otherwise using matplotlib,\n",
      "        Licensee agrees to be bound by the terms and conditions of this License\n",
      "        Agreement.\n",
      "Location: c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages\n",
      "Requires: contourpy, cycler, fonttools, kiwisolver, numpy, packaging, pillow, pyparsing, python-dateutil\n",
      "Required-by: mmdet, mmengine, pycocotools, seaborn\n"
     ]
    }
   ],
   "source": [
    "!pip show matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2889854f-13b6-42aa-a317-1354f8221c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (3.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a1e7069-7ac5-40b8-bc4e-a1d5b835075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module://matplotlib_inline.backend_inline\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.rcParams['backend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dfd290-e4b8-468a-aaec-bf289d03e685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fae7498-1e1e-4893-bf48-f0ee7c952644",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_log = 'tutorial_exps/20-epochs-benchmark/20240807_183412/vis_data/20240807_183412.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4ac97-0cbd-45a0-8d8d-571797213394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "229362df-2344-412c-9941-9667fa47c375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot curve of tutorial_exps/20-epochs-benchmark/20240807_183412/vis_data/20240807_183412.json, metric is loss\n",
      "save curve to: tutorial_exps/20-epochs-benchmark/20240807_183412/training_curves.png\n"
     ]
    }
   ],
   "source": [
    "!python mmdetection/tools/analysis_tools/analyze_logs.py plot_curve \\\n",
    "  --keys loss \\\n",
    "  --title \"Training Metrics\" \\\n",
    "  --legend \"Loss\" \\\n",
    "  --backend TkAgg \\\n",
    "  --style darkgrid \\\n",
    "  --out tutorial_exps/20-epochs-benchmark/20240807_183412/training_curves.png \\\n",
    "  {json_log}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66794880-5a51-40d7-8620-7833fdc397ed",
   "metadata": {},
   "source": [
    "#### Compute the average training speed.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1fd910c-1347-4dd9-91db-953820f6be93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Analyze train time of tutorial_exps/20-epochs-benchmark/20240807_183412/vis_data/20240807_183412.json-----\n",
      "slowest epoch 1, average time is 3.7813 s/iter\n",
      "fastest epoch 2, average time is 0.3693 s/iter\n",
      "time std over epochs is 0.7381\n",
      "average iter time: 0.5642 s/iter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python mmdetection/tools/analysis_tools/analyze_logs.py cal_train_time {json_log} --include-outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d60245-39af-48cb-9d46-b272633519e3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcb16a5d-7270-4383-bef2-80675507d4cb",
   "metadata": {},
   "source": [
    "## Result Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41006913-8114-4f57-aad7-da51f2b854c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: ahluwaliajyoti50 (ahluwaliajyoti50-university-of-sussex). Use `wandb login --relogin` to force relogin"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Tracking run with wandb version 0.17.5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.02s)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb: Run data is saved locally in C:\\Users\\ja683\\Downloads\\saf\\results\\20-epochs-benchmark\\vis_data\\20240807_195129\\vis_data\\wandb\\run-20240807_195140-vs11hnp4"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "wandb: Run `wandb offline` to turn off syncing."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "index created!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Syncing run brisk-armadillo-59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "08/07 19:51:36 - mmengine - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:  View project at https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:  View run at https://wandb.ai/ahluwaliajyoti50-university-of-sussex/SAF_Project/runs/vs11hnp4"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ja683\\AppData\\Roaming\\Python\\Python310\\site-packages\\mmengine\\visualization\\visualizer.py:760: UserWarning: Warning: The bbox is out of bounds, the drawn bbox may not be in the image"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ja683\\AppData\\Roaming\\Python\\Python310\\site-packages\\mmengine\\visualization\\visualizer.py:831: UserWarning: Warning: The polygon is out of bounds, the drawn polygon may not be in the image"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System environment:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sys.platform: win32\n",
      "    Python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1797828439\n",
      "    GPU 0: NVIDIA RTX A4000\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.66\n",
      "    MSVC: Microsoft (R) C/C++ Optimizing Compiler Version 19.35.32216.1 for x64\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.3.1\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 201703\n",
      "  - MSVC 192930154\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.7  (built against CUDA 12.2)\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.7, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.18.1\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1797828439\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/07 19:51:37 - mmengine - INFO - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'mmdetection/data/saf22/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=1,\n",
      "        max_keep_ckpts=1,\n",
      "        rule='greater',\n",
      "        save_best=[\n",
      "            'coco/bbox_mAP',\n",
      "            'coco/segm_mAP',\n",
      "        ],\n",
      "        save_last=True,\n",
      "        save_optimizer=True,\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=10, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = 'mmdetection/configs/htc/htc_x101_32x4d_fpn_16x1_20e_coco_20200318-de97ae01.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 20\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'ClassicalEvaporation',\n",
      "        'TansitionalMixing',\n",
      "        'DiffusiveMixing',\n",
      "        'spray',\n",
      "    ),\n",
      "    palette=[\n",
      "        (\n",
      "            13,\n",
      "            24,\n",
      "            103,\n",
      "        ),\n",
      "        (\n",
      "            167,\n",
      "            13,\n",
      "            13,\n",
      "        ),\n",
      "        (\n",
      "            91,\n",
      "            117,\n",
      "            249,\n",
      "        ),\n",
      "        (\n",
      "            203,\n",
      "            173,\n",
      "            55,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        base_width=4,\n",
      "        depth=101,\n",
      "        frozen_stages=1,\n",
      "        groups=32,\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://resnext101_32x4d', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNeXt'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_seg=True,\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                        0.2,\n",
      "                        0.2,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=4,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.05,\n",
      "                        0.05,\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=4,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.033,\n",
      "                        0.033,\n",
      "                        0.067,\n",
      "                        0.067,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=4,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "        ],\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        interleaved=True,\n",
      "        mask_head=[\n",
      "            dict(\n",
      "                conv_out_channels=256,\n",
      "                in_channels=256,\n",
      "                loss_mask=dict(\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "                num_classes=4,\n",
      "                num_convs=4,\n",
      "                type='HTCMaskHead',\n",
      "                with_conv_res=False),\n",
      "            dict(\n",
      "                conv_out_channels=256,\n",
      "                in_channels=256,\n",
      "                loss_mask=dict(\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "                num_classes=4,\n",
      "                num_convs=4,\n",
      "                type='HTCMaskHead'),\n",
      "            dict(\n",
      "                conv_out_channels=256,\n",
      "                in_channels=256,\n",
      "                loss_mask=dict(\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "                num_classes=4,\n",
      "                num_convs=4,\n",
      "                type='HTCMaskHead'),\n",
      "        ],\n",
      "        mask_info_flow=True,\n",
      "        mask_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        num_stages=3,\n",
      "        semantic_head=None,\n",
      "        semantic_roi_extractor=None,\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            0.5,\n",
      "            0.25,\n",
      "        ],\n",
      "        type='HybridTaskCascadeRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(\n",
      "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            mask_thr_binary=0.5,\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.001),\n",
      "        rpn=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=1000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    pos_iou_thr=0.5,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    pos_iou_thr=0.6,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    pos_iou_thr=0.7,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "        ],\n",
      "        rpn=dict(\n",
      "            allowed_border=0,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    type='HybridTaskCascade')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.0025, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=20,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            16,\n",
      "            19,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    dataset=dict(\n",
      "        ann_file='val/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val/'),\n",
      "        data_root='mmdetection/data/saf22/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'ClassicalEvaporation',\n",
      "                'TansitionalMixing',\n",
      "                'DiffusiveMixing',\n",
      "                'spray',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    13,\n",
      "                    24,\n",
      "                    103,\n",
      "                ),\n",
      "                (\n",
      "                    167,\n",
      "                    13,\n",
      "                    13,\n",
      "                ),\n",
      "                (\n",
      "                    91,\n",
      "                    117,\n",
      "                    249,\n",
      "                ),\n",
      "                (\n",
      "                    203,\n",
      "                    173,\n",
      "                    55,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='LoadAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_mask=True,\n",
      "                with_seg=True),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='mmdetection/data/saf22/val/annotation_coco.json',\n",
      "    backend_args=None,\n",
      "    classwise=True,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=20, type='EpochBasedTrainLoop', val_interval=3)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='train/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='train/'),\n",
      "        data_root='mmdetection/data/saf22/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'ClassicalEvaporation',\n",
      "                'TansitionalMixing',\n",
      "                'DiffusiveMixing',\n",
      "                'spray',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    13,\n",
      "                    24,\n",
      "                    103,\n",
      "                ),\n",
      "                (\n",
      "                    167,\n",
      "                    13,\n",
      "                    13,\n",
      "                ),\n",
      "                (\n",
      "                    91,\n",
      "                    117,\n",
      "                    249,\n",
      "                ),\n",
      "                (\n",
      "                    203,\n",
      "                    173,\n",
      "                    55,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='LoadAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_mask=True,\n",
      "                with_seg=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='val/annotation_coco.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val/'),\n",
      "        data_root='mmdetection/data/saf22/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'ClassicalEvaporation',\n",
      "                'TansitionalMixing',\n",
      "                'DiffusiveMixing',\n",
      "                'spray',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    13,\n",
      "                    24,\n",
      "                    103,\n",
      "                ),\n",
      "                (\n",
      "                    167,\n",
      "                    13,\n",
      "                    13,\n",
      "                ),\n",
      "                (\n",
      "                    91,\n",
      "                    117,\n",
      "                    249,\n",
      "                ),\n",
      "                (\n",
      "                    203,\n",
      "                    173,\n",
      "                    55,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='mmdetection/data/saf22/val/annotation_coco.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(type='TensorboardVisBackend'),\n",
      "        dict(\n",
      "            init_kwargs=dict(\n",
      "                config=dict(\n",
      "                    architecture='HTC_X101',\n",
      "                    batch_size=1,\n",
      "                    classes=(\n",
      "                        'ClassicalEvaporation',\n",
      "                        'TansitionalMixing',\n",
      "                        'DiffusiveMixing',\n",
      "                        'spray',\n",
      "                    ),\n",
      "                    dataset='SAF22',\n",
      "                    epochs=20,\n",
      "                    learning_rate=0.0025,\n",
      "                    optimizer='SGD',\n",
      "                    seed=0),\n",
      "                entity='ahluwaliajyoti50-university-of-sussex',\n",
      "                project='SAF_Project'),\n",
      "            type='WandbVisBackend'),\n",
      "    ])\n",
      "work_dir = './results/20-epochs-benchmark/vis_data'\n",
      "\n",
      "08/07 19:52:03 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/07 19:52:03 - mmengine - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "[                                                  ] 0/8, elapsed: 0s, ETA:\n",
      "[>>>>                              ] 1/8, 0.0 task/s, elapsed: 52s, ETA:   363s\n",
      "[>>>>>>>>                          ] 2/8, 0.0 task/s, elapsed: 76s, ETA:   228s\n",
      "[>>>>>>>>>>>>                      ] 3/8, 0.0 task/s, elapsed: 94s, ETA:   157s\n",
      "[>>>>>>>>>>>>>>>>                 ] 4/8, 0.0 task/s, elapsed: 108s, ETA:   108s\n",
      "[>>>>>>>>>>>>>>>>>>>>             ] 5/8, 0.0 task/s, elapsed: 113s, ETA:    68s\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>         ] 6/8, 0.1 task/s, elapsed: 118s, ETA:    39s\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 7/8, 0.1 task/s, elapsed: 131s, ETA:    19s\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 0.1 task/s, elapsed: 136s, ETA:     0sImage shape: (1536, 2072)\n",
      "Resized masks shape: (48, 1536, 2072)\n",
      "Image shape: (1536, 2072)\n",
      "Resized masks shape: (21, 1536, 2072)\n",
      "Image shape: (1536, 2072)\n",
      "Resized masks shape: (18, 1536, 2072)\n",
      "Image shape: (1536, 2072)\n",
      "Resized masks shape: (18, 1536, 2072)\n",
      "Image shape: (1536, 2072)\n",
      "Resized masks shape: (100, 1536, 2072)\n",
      "Image shape: (1536, 2072)\n",
      "Resized masks shape: (100, 1536, 2072)\n",
      "Image shape: (1536, 2072)\n",
      "Resized masks shape: (75, 1536, 2072)\n",
      "Image shape: (1536, 2072)\n",
      "Resized masks shape: (57, 1536, 2072)\n"
     ]
    }
   ],
   "source": [
    "!python mmdetection/tools/analysis_tools/analyze_results.py \\\n",
    "       mmdetection/configs/htc/htc_x101-32x4d_fpn_16xb1-20e_coco_saf.py \\\n",
    "       ./results/20-epochs-benchmark/results.pkl \\\n",
    "       ./results/20-epochs-benchmark/vis_data \\\n",
    "       --show\n",
    "# [Optional] Finish the wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d15d4c-4bb1-48ca-bf8a-d7290f98c49d",
   "metadata": {},
   "source": [
    "The masks are represented as a tensor of boolean values, these boolean tensors represent the masks directly, rather than as coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c504497b-bfdf-47fe-a620-40e4ed9b73de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06c23196-1d86-4a32-b0a9-8f9570f8cd63",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "655b1fc1-eee5-456a-a652-884553e4aaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "[                                                  ] 0/8, elapsed: 0s, ETA:\n",
      "[>>>>                            ] 1/8, 1002.7 task/s, elapsed: 0s, ETA:     0s\n",
      "[>>>>>>>>                        ] 2/8, 1003.4 task/s, elapsed: 0s, ETA:     0s\n",
      "[>>>>>>>>>>>>                    ] 3/8, 1003.3 task/s, elapsed: 0s, ETA:     0s\n",
      "[>>>>>>>>>>>>>>>>                ] 4/8, 1003.2 task/s, elapsed: 0s, ETA:     0s\n",
      "[>>>>>>>>>>>>>>>>>>>>            ] 5/8, 1254.1 task/s, elapsed: 0s, ETA:     0s\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>        ] 6/8, 1504.9 task/s, elapsed: 0s, ETA:     0s\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 7/8, 1405.7 task/s, elapsed: 0s, ETA:     0s\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 1606.6 task/s, elapsed: 0s, ETA:     0sFigure(1500x956.25)\n"
     ]
    }
   ],
   "source": [
    "!python mmdetection/tools/analysis_tools/confusion_matrix.py \\\n",
    "        mmdetection/configs/htc/htc_x101-32x4d_fpn_16xb1-20e_coco_saf.py \\\n",
    "        results/20-epochs-benchmark/results.pkl \\\n",
    "        results/20-epochs-benchmark --show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19277a64-ac6f-43a3-9d5c-87985016d432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ja683\\appdata\\local\\anaconda3\\envs\\mdet\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (3.9.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\ja683\\appdata\\local\\anaconda3\\envs\\mdet\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ja683\\appdata\\local\\anaconda3\\envs\\mdet\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ja683\\appdata\\local\\anaconda3\\envs\\mdet\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ja683\\appdata\\local\\anaconda3\\envs\\mdet\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\ja683\\appdata\\local\\anaconda3\\envs\\mdet\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ja683\\appdata\\local\\anaconda3\\envs\\mdet\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ja683\\appdata\\local\\anaconda3\\envs\\mdet\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ja683\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d8b8e-c5f0-4da3-9431-0951b5ae4c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3eed10e4-d502-4d4e-afa9-8e371b6f521f",
   "metadata": {},
   "source": [
    "## Eval Metric from results.pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "621fe26c-42f1-4fe5-ab24-e6f7d5bb72ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "08/07 20:16:56 - mmengine - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.336\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.317\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.900\n",
      "08/07 20:16:57 - mmengine - INFO - bbox_mAP_copypaste: 0.279 0.336 0.317 0.072 0.900 0.900\n",
      "08/07 20:16:57 - mmengine - INFO - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.800\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.866\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.867\n",
      "08/07 20:16:57 - mmengine - INFO - segm_mAP_copypaste: 0.275 0.341 0.319 0.077 0.800 0.866\n",
      "{'coco/bbox_mAP': 0.279, 'coco/bbox_mAP_50': 0.336, 'coco/bbox_mAP_75': 0.317, 'coco/bbox_mAP_s': 0.072, 'coco/bbox_mAP_m': 0.9, 'coco/bbox_mAP_l': 0.9, 'coco/segm_mAP': 0.275, 'coco/segm_mAP_50': 0.341, 'coco/segm_mAP_75': 0.319, 'coco/segm_mAP_s': 0.077, 'coco/segm_mAP_m': 0.8, 'coco/segm_mAP_l': 0.866}\n"
     ]
    }
   ],
   "source": [
    "!python mmdetection/tools/analysis_tools/eval_metric.py \\\n",
    "        mmdetection/configs/htc/htc_x101-32x4d_fpn_16xb1-20e_coco_saf.py \\\n",
    "        results/20-epochs-benchmark/results.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbe815-3175-45d1-b662-89d649fe2c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ab278-7a72-4da5-a4b7-c61fe0088bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b103240-8fd2-49b6-acd8-be37f9c594b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f9c470-afb2-4d89-ac41-0c204e629d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b46da2-8d9f-4e3e-9ab5-44dbadb3e58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae8349-4337-4773-be9d-19b7e9dc3667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd20a9-0c92-4faa-9058-278108e74d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbf7a7-ff6c-49da-86d4-d3b3540d37a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32804dd8-7473-4253-bb4d-d7278759ca3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad185a-d93b-448d-aa5a-5435f8daa393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdet",
   "language": "python",
   "name": "mdet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
